#!/usr/bin/env python3
"""
Extracteur API Prosuma RPOS - RECEPTION
R√©cup√®re les donn√©es via l'API delivery
"""

import requests
import os
import csv
import json
import logging
import shutil
import platform
from datetime import datetime, timedelta
from dotenv import load_dotenv
import urllib3
import sys

# Ajouter le r√©pertoire parent au path pour importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import load_shop_config, build_network_path, create_network_folder, SafeStreamHandler

# D√©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class ProsumaAPIReceptionExtractor:
    def __init__(self):
        """Initialise l'extracteur avec la configuration"""
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        load_dotenv(os.path.join(project_root, 'config.env'))
        
        self.username = os.getenv('PROSUMA_USER')
        self.password = os.getenv('PROSUMA_PASSWORD')
        
        if not self.username or not self.password:
            raise ValueError("PROSUMA_USER et PROSUMA_PASSWORD doivent √™tre configur√©s dans config.env")
        
        # Configuration du dossier de t√©l√©chargement
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.network_folder_base = os.getenv('DOWNLOAD_FOLDER_BASE', '\\10.0.70.169\\share\\FOFANA')
        
        # Configuration des magasins
        self.shop_config = load_shop_config(os.path.dirname(self.base_dir))
        self.shop_codes = list(self.shop_config.keys())
        
        # Configuration des dates (hier -> aujourd'hui par d√©faut)
        self.setup_dates()
        
        # Configuration du logging sera faite dans setup_logging()
        self.setup_logging()
        
        # Session HTTP
        self.session = requests.Session()
        self.session.auth = (self.username, self.password)
        self.session.verify = False

        print(f"Extracteur API initialis√© pour {self.username}")
        print(f"Magasins configur√©s: {self.shop_codes}")
        print(f"P√©riode: {self.start_date.strftime('%Y-%m-%d')} √† {self.end_date.strftime('%Y-%m-%d')}")

    def setup_logging(self):
        """Configure le logging avec fichier sur le r√©seau"""
        log_path = self.get_log_network_path()
        if log_path:
            log_file = os.path.join(log_path, f'prosuma_api_reception.log')
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(log_file, encoding='utf-8'),
                    SafeStreamHandler()
                ]
            )
        else:
            log_file = f'prosuma_api_reception.log'
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(log_file, encoding='utf-8'),
                    SafeStreamHandler()
                ]
            )
        
        # D√©finir les permissions pour permettre √† tous les utilisateurs d'√©crire
        from utils import set_log_file_permissions
        set_log_file_permissions(log_file)
        
        global logger
        logger = logging.getLogger(__name__)

    def setup_dates(self):
        """Configure les dates de filtrage (hier -> aujourd'hui par d√©faut)"""
        # Lire les dates depuis config.env
        date_start_str = os.getenv('DATE_START', '').strip()
        date_end_str = os.getenv('DATE_END', '').strip()
        
        if date_start_str and date_end_str:
            # Utiliser les dates personnalis√©es
            try:
                self.start_date = datetime.strptime(date_start_str, '%Y-%m-%d')
                self.end_date = datetime.strptime(date_end_str, '%Y-%m-%d')
                print(f"Dates personnalis√©es: {self.start_date.strftime('%Y-%m-%d')} √† {self.end_date.strftime('%Y-%m-%d')}")
            except ValueError:
                print("Format de date invalide, utilisation des dates par d√©faut")
                self.setup_default_dates()
        else:
            # Utiliser les dates par d√©faut (hier -> aujourd'hui)
            self.setup_default_dates()
    
    def setup_default_dates(self):
        """Configure les dates par d√©faut (hier -> aujourd'hui)"""
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        
        self.start_date = yesterday
        self.end_date = today
        
        print(f"Dates par d√©faut: {self.start_date.strftime('%Y-%m-%d')} √† {self.end_date.strftime('%Y-%m-%d')}")

    def get_network_path_for_shop(self, shop_code):
        """Retourne le chemin r√©seau pour un magasin sp√©cifique"""
        network_path = build_network_path(self.network_folder_base, "RECEPTION")
        if create_network_folder(network_path):
            return network_path
        return None
        
    def get_log_network_path(self):
        """Retourne le chemin r√©seau pour les logs"""
        if not self.network_folder_base:
            return None
        # Chemin: \\10.0.70.169\share\FOFANA\Etats Natacha\SCRIPT\LOG
        base = self.network_folder_base.replace('/', '\\')
        if base.endswith('\\'):
            base = base[:-1]
        log_path = f"{base}\\Etats Natacha\\SCRIPT\\LOG"
        if create_network_folder(log_path):
            return log_path
        return None

    def test_api_connection(self, base_url):
        """Teste la connexion √† l'API"""
        try:
            test_url = f"{base_url}/api/user/"
            response = self.session.get(test_url, timeout=10)
            if response.status_code == 200:
                logger.info(f"‚úÖ Connexion API r√©ussie: {base_url}")
                return True
            else:
                logger.error(f"‚ùå Erreur de connexion API {base_url}: {response.status_code} {response.reason}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erreur de connexion API {base_url}: {e}")
            return False

    def get_shop_info(self, base_url, shop_code):
        """R√©cup√®re les informations du magasin"""
        try:
            url = f"{base_url}/api/shop/"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # G√©rer la structure pagin√©e
                if isinstance(data, dict) and 'results' in data:
                    shops = data['results']
                elif isinstance(data, list):
                    shops = data
                else:
                    logger.error(f"‚ùå Format de r√©ponse invalide: {type(data)}")
                    return None
                
                for shop in shops:
                    if str(shop.get('reference')) == str(shop_code):
                        logger.info(f"‚úÖ Magasin {shop_code} trouv√©: {shop.get('name', 'N/A')}")
                        return shop
                
                logger.warning(f"‚ö†Ô∏è Magasin {shop_code} non trouv√© dans la liste")
                return None
            else:
                logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des magasins: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des informations du magasin: {e}")
            return None
    
    def get_order_info(self, base_url, order_id):
        """R√©cup√®re les informations compl√®tes d'une commande via l'API /api/supplier_order/{id}/"""
        if not order_id:
            return None
        
        try:
            # Essayer d'abord avec l'endpoint direct
            url = f"{base_url}/api/supplier_order/{order_id}/"
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                order_data = response.json()
                if isinstance(order_data, dict):
                    return order_data
            
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration de la commande {order_id}: {e}")
            return None
    
    def get_supplier_info(self, base_url, supplier_id):
        """R√©cup√®re les informations compl√®tes d'un fournisseur via l'API /api/supplier/{id}/"""
        if not supplier_id:
            return None
        
        try:
            # Essayer d'abord avec l'endpoint direct
            url = f"{base_url}/api/supplier/{supplier_id}/"
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                supplier_data = response.json()
                if isinstance(supplier_data, dict):
                    return supplier_data
            
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration du fournisseur {supplier_id}: {e}")
            return None
    
    def enrich_deliveries_with_order_info(self, base_url, deliveries):
        """Enrichit les r√©ceptions avec les informations compl√®tes de la commande (is_direct, is_central)"""
        if not deliveries:
            return deliveries
        
        logger.info(f"üîç Enrichissement des r√©ceptions avec les informations des commandes...")
        
        # Collecter tous les IDs de commandes uniques
        order_ids = set()
        for delivery in deliveries:
            order = delivery.get('order')
            if isinstance(order, dict):
                order_id = order.get('id')
                if order_id:
                    order_ids.add(order_id)
            elif isinstance(order, str):
                # Si order est une URL, extraire l'ID
                if order.endswith('/'):
                    order = order[:-1]
                order_id = order.split('/')[-1]
                if order_id:
                    order_ids.add(order_id)
        
        logger.info(f"   üìä {len(order_ids)} commande(s) unique(s) √† r√©cup√©rer")
        
        # Cr√©er un cache pour les informations des commandes
        order_cache = {}
        supplier_cache = {}
        
        for order_id in order_ids:
            order_info = self.get_order_info(base_url, order_id)
            if order_info:
                order_cache[order_id] = order_info
                
                # R√©cup√©rer aussi les informations du fournisseur si disponible
                supplier = order_info.get('supplier', {})
                supplier_id = None
                
                if isinstance(supplier, dict):
                    supplier_id = supplier.get('id')
                elif isinstance(supplier, str):
                    if supplier.endswith('/'):
                        supplier = supplier[:-1]
                    supplier_id = supplier.split('/')[-1]
                
                if supplier_id and supplier_id not in supplier_cache:
                    supplier_info = self.get_supplier_info(base_url, supplier_id)
                    if supplier_info:
                        supplier_cache[supplier_id] = supplier_info
        
        logger.info(f"   ‚úÖ {len(order_cache)} commande(s) r√©cup√©r√©e(s)")
        logger.info(f"   ‚úÖ {len(supplier_cache)} fournisseur(s) r√©cup√©r√©(s)")
        
        # Enrichir les r√©ceptions avec les informations de la commande
        enriched_count = 0
        for delivery in deliveries:
            order = delivery.get('order')
            order_id = None
            
            if isinstance(order, dict):
                order_id = order.get('id')
            elif isinstance(order, str):
                if order.endswith('/'):
                    order = order[:-1]
                order_id = order.split('/')[-1]
            
            if order_id and order_id in order_cache:
                order_info = order_cache[order_id]
                
                # Pour les r√©ceptions : is_central=True = commande directe, is_central=False = commande r√©assort
                # Enrichir le supplier dans order avec is_central
                supplier = order_info.get('supplier', {})
                supplier_id = None
                
                if isinstance(supplier, dict):
                    supplier_id = supplier.get('id')
                elif isinstance(supplier, str):
                    if supplier.endswith('/'):
                        supplier = supplier[:-1]
                    supplier_id = supplier.split('/')[-1]
                
                if supplier_id and supplier_id in supplier_cache:
                    supplier_info = supplier_cache[supplier_id]
                    supplier_is_central = supplier_info.get('is_central', False)
                    
                    # Enrichir l'objet order dans la r√©ception
                    if isinstance(delivery.get('order'), dict):
                        if isinstance(delivery.get('order', {}).get('supplier'), dict):
                            delivery['order']['supplier']['is_central'] = supplier_is_central
                    
                    # Pour les r√©ceptions : is_central=True = commande directe, is_central=False = commande r√©assort
                    # supplier.is_central=True = fournisseur central (r√©assort)
                    # supplier.is_central=False = fournisseur non central (direct)
                    # Donc pour la r√©ception : is_central = NOT supplier.is_central
                    delivery['is_central'] = not supplier_is_central
                
                # Ajouter aussi is_direct si disponible dans order_info
                if 'is_direct' in order_info:
                    delivery['is_direct'] = order_info.get('is_direct')
                    if isinstance(delivery.get('order'), dict):
                        delivery['order']['is_direct'] = order_info.get('is_direct')
                
                enriched_count += 1
        
        logger.info(f"   ‚úÖ {enriched_count} r√©ception(s) enrichie(s) avec is_direct/is_central")
        return deliveries

    
    def count_total_records(self, base_url, shop_id, page_size=1000):
        """Compte le nombre total d'enregistrements disponibles (r√©ceptions de commandes directes)"""
        try:
            url = f"{base_url}/api/delivery/"
            params = {
                'shop': shop_id,
                'page_size': page_size,
                'page': 1,
                'is_central': 'true'  # Filtrer pour les r√©ceptions de commandes directes (is_central=true = commande directe)
            }
            
            # Ajouter les param√®tres de date si disponibles
            if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S')
                params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S')
            
            response = self.session.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                total_count = data.get('count', 0)
                return total_count
            else:
                logger.error(f"‚ùå Erreur lors du comptage: {response.status_code}")
                return 0
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du comptage: {e}")
            return 0

    def get_data(self, base_url, shop_id, page_size=1000):
        """R√©cup√®re les r√©ceptions de commandes directes avec pagination compl√®te"""
        # D'abord, compter le nombre total d'enregistrements
        logger.info("üîç Comptage du nombre total de r√©ceptions de commandes directes...")
        total_records = self.count_total_records(base_url, shop_id, page_size)
        
        if total_records == 0:
            logger.warning("‚ö†Ô∏è Aucune r√©ception de commande directe trouv√©e")
            return []
        
        # Afficher le cadre avec le nombre total
        logger.info("=" * 60)
        logger.info(f"üìä INFORMATIONS D'EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"üìä Total r√©ceptions de commandes directes disponibles: {total_records:,}")
        logger.info(f"üìÖ P√©riode: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"üè™ Magasin: {shop_id}")
        logger.info("=" * 60)
        
        all_data = []
        page = 1
        total_pages = (total_records + page_size - 1) // page_size  # Calcul du nombre total de pages
        
        logger.info(f"üîç Filtres API appliqu√©s:")
        logger.info(f"   - is_central: true (r√©ceptions de commandes directes)")
        
        try:
            while page <= total_pages:
                url = f"{base_url}/api/delivery/"
                params = {
                    'shop': shop_id,
                    'page_size': page_size,
                    'page': page,
                    'is_central': 'true'  # Filtrer pour les r√©ceptions de commandes directes (is_central=true = commande directe)
                }
                
                # Ajouter les param√®tres de date si disponibles
                if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                    params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S')
                    params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S')
                
                # Afficher la progression
                progress_percent = (page - 1) * 100 // total_pages if total_pages > 0 else 0
                logger.info(f"üìÑ R√©cup√©ration page {page}/{total_pages} ({progress_percent}%) - {len(all_data):,}/{total_records:,} enregistrements...")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('results', [])
                    
                    if not items:
                        logger.info(f"  ‚úÖ Derni√®re page atteinte (page {page}) - Aucun enregistrement retourn√©")
                        break
                    
                    all_data.extend(items)
                    logger.info(f"  ‚úÖ Page {page}: {len(items)} r√©ceptions r√©cup√©r√©es (total: {len(all_data):,}/{total_records:,})")
                    
                    # V√©rifier si on a r√©cup√©r√© tous les enregistrements ou si on est √† la derni√®re page
                    if len(all_data) >= total_records:
                        logger.info(f"  ‚úÖ Toutes les r√©ceptions r√©cup√©r√©es (page {page}/{total_pages})")
                        break
                    
                    # Si on est √† la derni√®re page calcul√©e, on arr√™te
                    if page >= total_pages:
                        logger.info(f"  ‚úÖ Derni√®re page atteinte (page {page}/{total_pages})")
                        break
                    
                    # Continuer avec la page suivante
                    page += 1
                else:
                    logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {response.status_code}")
                    # Continuer avec la page suivante en cas d'erreur temporaire
                    if response.status_code == 500 or response.status_code == 503:
                        logger.warning(f"‚ö†Ô∏è Erreur serveur, tentative de continuer...")
                        page += 1
                        continue
                    break
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {e}")
        
        # Enrichir les r√©ceptions avec les informations de la commande (order) pour obtenir is_direct et is_central
        if all_data:
            logger.info(f"üîç Enrichissement des r√©ceptions avec les informations des commandes...")
            all_data = self.enrich_deliveries_with_order_info(base_url, all_data)
        
        # Filtre de s√©curit√© suppl√©mentaire : v√©rifier que les r√©ceptions sont bien des commandes directes
        original_count = len(all_data)
        filtered_data = []
        reassort_excluded = 0
        
        if all_data:
            # Analyser la premi√®re r√©ception pour voir la structure apr√®s enrichissement
            first_delivery = all_data[0]
            has_is_central = 'is_central' in first_delivery
            has_is_direct = 'is_direct' in first_delivery
            
            # V√©rifier aussi dans order si les champs ne sont pas directement dans delivery
            if not has_is_central and not has_is_direct:
                order = first_delivery.get('order', {})
                if isinstance(order, dict):
                    has_is_central = 'is_central' in order or (isinstance(order.get('supplier'), dict) and 'is_central' in order.get('supplier', {}))
                    has_is_direct = 'is_direct' in order
            
            logger.info(f"üîç Analyse des champs API (apr√®s enrichissement):")
            logger.info(f"   - is_central pr√©sent: {'‚úÖ OUI' if has_is_central else '‚ùå NON'}")
            logger.info(f"   - is_direct pr√©sent: {'‚úÖ OUI' if has_is_direct else '‚ùå NON'}")
            
            if has_is_central:
                # Filtre de s√©curit√© : v√©rifier is_central=True (commande directe)
                # is_central=True = commande directe
                # is_central=False = commande r√©assort
                for delivery in all_data:
                    is_central = delivery.get('is_central', None)
                    
                    # Si pas dans delivery, chercher dans order
                    if is_central is None:
                        order = delivery.get('order', {})
                        if isinstance(order, dict):
                            is_central = order.get('is_central', None)
                            if is_central is None:
                                supplier = order.get('supplier', {})
                                if isinstance(supplier, dict):
                                    is_central = supplier.get('is_central', None)
                    
                    if is_central is not None:
                        if is_central:  # is_central=True = commande directe
                            filtered_data.append(delivery)
                        else:
                            reassort_excluded += 1
                            logger.debug(f"‚ùå R√©ception r√©assort exclue par filtre de s√©curit√©: {delivery.get('delivery_number', delivery.get('id', 'N/A'))} (is_central=False)")
                    else:
                        # Si is_central n'est pas d√©fini, on garde (le filtre API is_central=true a d√©j√† filtr√©)
                        filtered_data.append(delivery)
            elif has_is_direct:
                # Filtre de s√©curit√© : v√©rifier is_direct=True (commande directe)
                for delivery in all_data:
                    is_direct = delivery.get('is_direct', None)
                    
                    # Si pas dans delivery, chercher dans order
                    if is_direct is None:
                        order = delivery.get('order', {})
                        if isinstance(order, dict):
                            is_direct = order.get('is_direct', None)
                    
                    if is_direct is not None:
                        if is_direct:  # is_direct=True = commande directe
                            filtered_data.append(delivery)
                        else:
                            reassort_excluded += 1
                            logger.debug(f"‚ùå R√©ception r√©assort exclue par filtre de s√©curit√©: {delivery.get('delivery_number', delivery.get('id', 'N/A'))} (is_direct=False)")
                    else:
                        # Si is_direct n'est pas d√©fini, on garde (le filtre API is_direct=true a d√©j√† filtr√©)
                        filtered_data.append(delivery)
            else:
                # Les champs n'existent toujours pas apr√®s enrichissement
                logger.warning(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ATTENTION: Les champs is_central et is_direct n'existent toujours pas apr√®s enrichissement ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
                logger.warning(f"   On fait confiance au filtre API (is_central=true)")
                logger.warning(f"   Toutes les {original_count} r√©ceptions sont accept√©es comme commandes directes")
                filtered_data = all_data.copy()
        
        all_data = filtered_data
        filtered_count = len(all_data)
        
        if reassort_excluded > 0:
            logger.warning(f"‚ö†Ô∏è {reassort_excluded} r√©ception(s) r√©assort exclue(s) par le filtre de s√©curit√©")
        
        # Afficher le r√©sum√© final
        logger.info("=" * 60)
        logger.info(f"‚úÖ R√âSUM√â EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"üìä R√©ceptions de commandes directes trouv√©es: {total_records:,}")
        logger.info(f"üì• R√©ceptions extraites (apr√®s filtre de s√©curit√©): {filtered_count:,}")
        if total_records > 0:
            logger.info(f"üìà Taux de r√©ussite: {(filtered_count/total_records*100):.1f}%")
        logger.info("=" * 60)
        
        return all_data

    def _flatten_value(self, value, max_length=1000):
        """Convertit une valeur complexe (dict, list) en cha√Æne JSON format√©e pour le CSV."""
        if value is None:
            return ''
        elif isinstance(value, bool):
            return 'Oui' if value else 'Non'
        elif isinstance(value, (int, float)):
            return str(value)
        elif isinstance(value, str):
            # Nettoyer les retours √† la ligne et caract√®res sp√©ciaux
            cleaned = value.replace('\n', ' ').replace('\r', ' ').replace(';', ',')
            if len(cleaned) > max_length:
                return cleaned[:max_length] + '...'
            return cleaned
        elif isinstance(value, dict):
            # Pour les dictionnaires, cr√©er une repr√©sentation plus lisible
            try:
                json_str = json.dumps(value, ensure_ascii=False, indent=None)
                if len(json_str) > max_length:
                    return json_str[:max_length] + '...'
                return json_str
            except (TypeError, ValueError):
                return str(value)
        elif isinstance(value, list):
            # Pour les listes, cr√©er une repr√©sentation plus lisible
            if not value:
                return ''
            try:
                # Si c'est une liste de dictionnaires, extraire les champs importants
                if value and isinstance(value[0], dict):
                    # Extraire les champs cl√©s de chaque √©l√©ment
                    simplified = []
                    for item in value[:10]:  # Limiter √† 10 √©l√©ments
                        if isinstance(item, dict):
                            # Extraire les champs les plus importants
                            item_str = {}
                            for key in ['id', 'name', 'reference', 'quantity', 'price', 'barcode', 'ean']:
                                if key in item:
                                    item_str[key] = item[key]
                            if item_str:
                                simplified.append(item_str)
                    if simplified:
                        json_str = json.dumps(simplified, ensure_ascii=False, indent=None)
                        if len(json_str) > max_length:
                            return json_str[:max_length] + '...'
                        return json_str
                
                # Sinon, convertir en JSON simple
                json_str = json.dumps(value, ensure_ascii=False, indent=None)
                if len(json_str) > max_length:
                    return json_str[:max_length] + '...'
                return json_str
            except (TypeError, ValueError):
                return str(value)
        else:
            return str(value)
    
    def _flatten_nested_object(self, obj, prefix='', max_depth=3, top_level_keys=None):
        """Aplatit un objet imbriqu√© en dictionnaire plat avec pr√©fixes.
        
        Args:
            obj: L'objet dictionnaire √† aplatir
            prefix: Pr√©fixe √† ajouter aux noms de champs
            max_depth: Profondeur maximale d'aplatissement
            top_level_keys: Set des cl√©s de niveau sup√©rieur pour √©viter les doublons
        """
        if not isinstance(obj, dict) or max_depth <= 0:
            return {}
        
        if top_level_keys is None:
            top_level_keys = set()
        
        flattened = {}
        for key, value in obj.items():
            # Si c'est un champ de niveau sup√©rieur et qu'on n'a pas de pr√©fixe, on le garde tel quel
            # Sinon, on ajoute un pr√©fixe pour √©viter les conflits
            if prefix:
                field_name = f"{prefix}_{key}"
            else:
                # Si c'est un champ de niveau sup√©rieur, on le garde tel quel
                # Sinon, on ajoute un pr√©fixe bas√© sur la cl√© parente
                field_name = key
            
            if isinstance(value, dict):
                # R√©cursivement aplatir les dictionnaires imbriqu√©s
                nested = self._flatten_nested_object(value, field_name, max_depth - 1, top_level_keys)
                flattened.update(nested)
                
                # Ajouter aussi les champs les plus importants directement avec des noms clairs
                # Toujours utiliser un pr√©fixe pour √©viter les conflits avec les champs de niveau sup√©rieur
                important_fields = {
                    'id': f"{field_name}_id",
                    'name': f"{field_name}_name",
                    'reference': f"{field_name}_reference",
                    'code': f"{field_name}_code",
                    'email': f"{field_name}_email",
                    'phone': f"{field_name}_phone",
                    'address': f"{field_name}_address",
                    'is_central': f"{field_name}_is_central",
                    'is_direct': f"{field_name}_is_direct",
                    'status': f"{field_name}_status",
                    'status_display': f"{field_name}_status_display",
                    'date': f"{field_name}_date",
                    'delivery_date': f"{field_name}_delivery_date",
                    'delivery_number': f"{field_name}_delivery_number",
                    'validation_date': f"{field_name}_validation_date",
                    'created_at': f"{field_name}_created_at",
                    'updated_at': f"{field_name}_updated_at",
                    'validated_by': f"{field_name}_validated_by",
                    'validated': f"{field_name}_validated",
                    'total': f"{field_name}_total",
                    'total_ht': f"{field_name}_total_ht",
                    'total_ttc': f"{field_name}_total_ttc",
                    'quantity': f"{field_name}_quantity"
                }
                
                for field_key, flat_name in important_fields.items():
                    if field_key in value:
                        # V√©rifier que le nom de champ aplati ne cr√©e pas de doublon avec un champ de niveau sup√©rieur
                        if flat_name not in top_level_keys:
                            flattened[flat_name] = value.get(field_key)
            elif isinstance(value, list) and value:
                if isinstance(value[0], dict):
                    # Pour les listes de dictionnaires, extraire les champs importants du premier √©l√©ment
                    count_field = f"{field_name}_count"
                    if count_field not in top_level_keys:
                        flattened[count_field] = len(value)
                    if value:
                        first_item = value[0]
                        # Extraire les champs importants du premier √©l√©ment
                        for field_key in ['id', 'name', 'reference', 'quantity', 'price', 'barcode', 'ean']:
                            if field_key in first_item:
                                first_field_name = f"{field_name}_first_{field_key}"
                                if first_field_name not in top_level_keys:
                                    flattened[first_field_name] = first_item.get(field_key)
                else:
                    # Liste de valeurs simples - seulement si le champ n'existe pas d√©j√† au niveau sup√©rieur
                    if field_name not in top_level_keys or prefix:
                        flattened[field_name] = ', '.join(str(v) for v in value[:10])  # Limiter √† 10 √©l√©ments
            else:
                # Pour les valeurs simples, seulement ajouter si le champ n'existe pas d√©j√† au niveau sup√©rieur
                # ou si on a un pr√©fixe (ce qui signifie qu'on est dans un objet imbriqu√©)
                if field_name not in top_level_keys or prefix:
                    flattened[field_name] = value
        
        return flattened
    
    def _get_all_fields_from_data(self, data):
        """D√©tecte tous les champs disponibles dans les donn√©es, y compris les champs aplatis des objets imbriqu√©s."""
        all_fields = set()
        flattened_fields = set()
        
        # Liste des champs importants √† toujours inclure (m√™me s'ils ne sont pas d√©tect√©s)
        # Bas√©e sur la documentation API /api/delivery/
        important_fields_always = [
            # Champs de base (selon doc API)
            'id',                           # uuid
            'name',                         # nom affich√©
            'delivery_number',              # N¬∞ de bon livraison
            'date',                         # Date (obligatoire)
            'validation_date',             # Date validation
            'validated',                    # Valid√© (boolean)
            'delivery_type',                # Type de r√©ception (1=r√©ception, 2=retour fournisseur)
            'is_central',                   # Is central
            'created_at',                   # Date creation
            'updated_at',                   # Date modification
            'deleted_at',                   # Date suppression
            # Champs quantit√©s et prix (selon doc API)
            'total_quantity',               # Total quantity
            'smart_quantity',               # Smart quantity
            'total_buying_price_excl_tax_perf',  # Total buying price excl tax perf
            'total_buying_price_incl_tax', # Total buying price incl tax
            'total_buying_price_excl_tax', # Total buying price excl tax
            # Champs commande
            'order_reference',              # R√©f. Commande (extrait de order)
            'order_external_reference',     # R√©f. externe (extrait de order)
            'order_status',                 # Statut Commande
            # Champs suppl√©mentaires
            'delivery_date',                # Date de livraison (alias)
            'reception_date',               # Date de r√©ception (alias)
            'created_by',                   # Cr√©√©e par
            'validated_by',                 # Valid√©e par
            # Champs shop (aplatis)
            'shop_id',
            'shop_name',
            'shop_reference',
            'shop_email',
            'shop_url',
            'shop_is_warehouse',
            'shop_gps',
            # Champs supplier (aplatis)
            'supplier_id',
            'supplier_name',
            'supplier_code',
            'supplier_email',
            'supplier_url',
            'supplier_delivery_time_days',
            # Champs suppl√©mentaires de la doc
            'is_order_finalized',          # Is order finalized
            'has_production_batch',         # Has production batch
            'pda_uri',                      # Pda uri
            'training',                     # Training
            'origin_delivery'              # R√©ception d'origine
        ]
        
        for item in data:
            if isinstance(item, dict):
                # Ajouter les champs directs
                all_fields.update(item.keys())
                
                # Aplatir les objets imbriqu√©s pour d√©tecter tous les champs possibles
                flattened = self._flatten_nested_object(item, max_depth=2)
                flattened_fields.update(flattened.keys())
        
        # Combiner les champs directs et aplatis, en √©liminant les doublons
        # Priorit√© aux champs directs (si un champ existe √† la fois en direct et en aplati, on garde le direct)
        combined_fields = sorted(list(all_fields | flattened_fields))
        
        # Ajouter les champs importants s'ils ne sont pas d√©j√† pr√©sents
        for important_field in important_fields_always:
            if important_field not in combined_fields:
                combined_fields.append(important_field)
        
        # V√©rifier et supprimer les doublons explicites
        seen = set()
        unique_fields = []
        for field in combined_fields:
            if field not in seen:
                seen.add(field)
                unique_fields.append(field)
        
        return unique_fields

def export_to_csv(self, data, shop_code, shop_name):
        """Exporte les donn√©es vers un fichier CSV avec formatage am√©lior√©"""
        if not data:
            logger.warning(f"Aucune donn√©e √† exporter pour le magasin {shop_code}")
            return None
        
        # Cr√©er le dossier r√©seau
        network_path = self.get_network_path_for_shop(shop_code)
        if not network_path:
            logger.error(f"Impossible de cr√©er le dossier r√©seau pour le magasin {shop_code}")
            return None
        
        # Cr√©er un fichier temporaire local
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'export_reception_{shop_code}_{timestamp}.csv'
        local_filepath = os.path.join(self.base_dir, filename)
        
        # D√©tecter tous les champs disponibles (y compris les champs aplatis)
        api_fields = self._get_all_fields_from_data(data)
        
        # S'assurer qu'il n'y a pas de doublons dans les fieldnames
        fieldnames_set = set(api_fields)
        if len(fieldnames_set) != len(api_fields):
            logger.warning(f"‚ö†Ô∏è Doublons d√©tect√©s dans les champs API: {len(api_fields)} champs, {len(fieldnames_set)} uniques")
            api_fields = sorted(list(fieldnames_set))
        
        logger.info(f"üìã Champs d√©tect√©s dans l'API: {len(api_fields)} champs uniques")
        logger.info(f"   Champs: {', '.join(api_fields[:15])}{'...' if len(api_fields) > 15 else ''}")
        
        # Construire la liste des en-t√™tes: d'abord les champs API, puis shop_code et shop_name
        # V√©rifier que shop_code et shop_name ne sont pas d√©j√† dans api_fields
        final_fieldnames = api_fields.copy()
        if 'shop_code' not in final_fieldnames:
            final_fieldnames.append('shop_code')
        if 'shop_name' not in final_fieldnames:
            final_fieldnames.append('shop_name')
        
        fieldnames = final_fieldnames
        
        try:
            # Cr√©er le fichier CSV local
            with open(local_filepath, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')
                writer.writeheader()
                
                for item in data:
                    row = {}
                    
                    # Aplatir l'item pour extraire tous les champs (y compris les objets imbriqu√©s)
                    # Passer les cl√©s de niveau sup√©rieur pour √©viter les doublons
                    top_level_keys = set(item.keys()) if isinstance(item, dict) else set()
                    flattened_item = self._flatten_nested_object(item, max_depth=3, top_level_keys=top_level_keys)
                    
                    # Fusionner l'item original avec l'item aplati
                    # Les champs directs ont priorit√© sur les champs aplatis
                    merged_item = {**flattened_item, **item}
                    
                    # Extraire manuellement les champs importants pour s'assurer qu'ils sont bien pr√©sents
                    # Num√©ro de bon de livraison
                    if 'delivery_number' not in merged_item:
                        merged_item['delivery_number'] = item.get('delivery_number', item.get('number', ''))
                    
                    # Extraire les informations de la commande (order)
                    order = item.get('order', {})
                    if not order or (isinstance(order, str) and not order.strip()):
                        order = {}
                    
                    # R√©f√©rence commande (depuis order)
                    if 'order_reference' not in merged_item:
                        if isinstance(order, dict) and order:
                            merged_item['order_reference'] = order.get('reference', order.get('code_com', ''))
                        else:
                            merged_item['order_reference'] = ''
                    
                    # R√©f√©rence externe (depuis order)
                    if 'order_external_reference' not in merged_item:
                        if isinstance(order, dict) and order:
                            merged_item['order_external_reference'] = order.get('external_reference', '')
                        else:
                            merged_item['order_external_reference'] = ''
                    
                    # Statut commande (depuis order)
                    if 'order_status' not in merged_item:
                        if isinstance(order, dict) and order:
                            merged_item['order_status'] = order.get('status_display', order.get('status', ''))
                        else:
                            # Si pas de commande, utiliser le statut de la r√©ception elle-m√™me
                            merged_item['order_status'] = item.get('order_status', 'Pas de commande associ√©e')
                    
                    # Aplatir les objets shop et supplier pour √©viter les JSON bruts
                    # Shop
                    shop = item.get('shop', {})
                    if isinstance(shop, dict) and shop:
                        if 'shop_id' not in merged_item:
                            merged_item['shop_id'] = shop.get('id', '')
                        if 'shop_name' not in merged_item:
                            merged_item['shop_name'] = shop.get('name', '')
                        if 'shop_reference' not in merged_item:
                            merged_item['shop_reference'] = shop.get('reference', '')
                        if 'shop_email' not in merged_item:
                            merged_item['shop_email'] = shop.get('email', '')
                        if 'shop_url' not in merged_item:
                            merged_item['shop_url'] = shop.get('url', '')
                        if 'shop_is_warehouse' not in merged_item:
                            merged_item['shop_is_warehouse'] = 'Oui' if shop.get('is_warehouse', False) else 'Non'
                        if 'shop_gps' not in merged_item:
                            merged_item['shop_gps'] = shop.get('gps', '')
                    
                    # Supplier
                    supplier = item.get('supplier', {})
                    if isinstance(supplier, dict) and supplier:
                        if 'supplier_id' not in merged_item:
                            merged_item['supplier_id'] = supplier.get('id', '')
                        if 'supplier_name' not in merged_item:
                            merged_item['supplier_name'] = supplier.get('name', '')
                        if 'supplier_code' not in merged_item:
                            merged_item['supplier_code'] = supplier.get('code', '')
                        if 'supplier_email' not in merged_item:
                            merged_item['supplier_email'] = supplier.get('email', '')
                        if 'supplier_url' not in merged_item:
                            merged_item['supplier_url'] = supplier.get('url', '')
                        if 'supplier_delivery_time_days' not in merged_item:
                            merged_item['supplier_delivery_time_days'] = supplier.get('delivery_time_days', '')
                    
                    # Date de livraison
                    if 'delivery_date' not in merged_item:
                        merged_item['delivery_date'] = item.get('delivery_date', item.get('date', ''))
                    
                    # Date de r√©ception
                    if 'reception_date' not in merged_item:
                        merged_item['reception_date'] = item.get('created_at', item.get('date', ''))
                    
                    # Date de validation
                    if 'validation_date' not in merged_item:
                        merged_item['validation_date'] = item.get('validation_date', item.get('validated_at', ''))
                    
                    # Cr√©√©e par
                    if 'created_by' not in merged_item:
                        merged_item['created_by'] = item.get('created_by', item.get('created_by_name', ''))
                    
                    # Valid√© par
                    if 'validated_by' not in merged_item:
                        merged_item['validated_by'] = item.get('validated_by', item.get('validated_by_name', ''))
                    
                    # Valid√© (Oui/Non)
                    if 'validated' not in merged_item:
                        validated = item.get('validated', item.get('is_validated', False))
                        merged_item['validated'] = 'Oui' if validated else 'Non'
                    
                    # Date (date principale de la r√©ception) - obligatoire selon doc
                    if 'date' not in merged_item:
                        merged_item['date'] = item.get('date', item.get('delivery_date', item.get('created_at', '')))
                    
                    # Champs selon documentation API /api/delivery/
                    # name (nom affich√©)
                    if 'name' not in merged_item:
                        merged_item['name'] = item.get('name', '')
                    
                    # delivery_type (1=r√©ception, 2=retour fournisseur)
                    if 'delivery_type' not in merged_item:
                        delivery_type = item.get('delivery_type', '')
                        if delivery_type == 1:
                            merged_item['delivery_type'] = 'R√©ception'
                        elif delivery_type == 2:
                            merged_item['delivery_type'] = 'Retour fournisseur'
                        else:
                            merged_item['delivery_type'] = str(delivery_type) if delivery_type else ''
                    
                    # total_quantity (Total quantity)
                    if 'total_quantity' not in merged_item:
                        merged_item['total_quantity'] = item.get('total_quantity', '')
                    
                    # smart_quantity (Smart quantity)
                    if 'smart_quantity' not in merged_item:
                        merged_item['smart_quantity'] = item.get('smart_quantity', '')
                    
                    # total_buying_price_excl_tax_perf
                    if 'total_buying_price_excl_tax_perf' not in merged_item:
                        merged_item['total_buying_price_excl_tax_perf'] = item.get('total_buying_price_excl_tax_perf', '')
                    
                    # total_buying_price_incl_tax
                    if 'total_buying_price_incl_tax' not in merged_item:
                        merged_item['total_buying_price_incl_tax'] = item.get('total_buying_price_incl_tax', '')
                    
                    # total_buying_price_excl_tax
                    if 'total_buying_price_excl_tax' not in merged_item:
                        merged_item['total_buying_price_excl_tax'] = item.get('total_buying_price_excl_tax', '')
                    
                    # is_central (selon doc)
                    if 'is_central' not in merged_item:
                        is_central = item.get('is_central', False)
                        merged_item['is_central'] = 'Oui' if is_central else 'Non'
                    
                    # is_order_finalized
                    if 'is_order_finalized' not in merged_item:
                        is_finalized = item.get('is_order_finalized', False)
                        merged_item['is_order_finalized'] = 'Oui' if is_finalized else 'Non'
                    
                    # has_production_batch
                    if 'has_production_batch' not in merged_item:
                        has_batch = item.get('has_production_batch', False)
                        merged_item['has_production_batch'] = 'Oui' if has_batch else 'Non'
                    
                    # training
                    if 'training' not in merged_item:
                        training = item.get('training', False)
                        merged_item['training'] = 'Oui' if training else 'Non'
                    
                    # Ajouter tous les champs d√©tect√©s
                    for field in api_fields:
                        if field in merged_item:
                            row[field] = self._flatten_value(merged_item[field])
                        else:
                            row[field] = ''
                    
                    # Ajouter les champs suppl√©mentaires
                    row['shop_code'] = shop_code
                    row['shop_name'] = shop_name
                    writer.writerow(row)
            
            logger.info(f"‚úÖ Fichier CSV cr√©√© localement: {local_filepath}")
            logger.info(f"   {len(data)} √©l√©ments export√©s")
            logger.info(f"   {len(fieldnames)} colonnes par √©l√©ment")
            
            # Copier vers le r√©seau et supprimer le fichier local
            network_filepath = os.path.join(network_path, filename)
            shutil.copy2(local_filepath, network_filepath)
            logger.info(f"‚úÖ Fichier copi√© sur le r√©seau: {network_filepath}")
            
            # Supprimer le fichier local
            os.remove(local_filepath)
            logger.info(f"üóëÔ∏è Fichier local supprim√©")
            
            return network_filepath
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'export CSV: {e}")
            return None

    def extract_shop(self, shop_code):
        """Extrait les donn√©es pour un magasin sp√©cifique"""
        shop_info = self.shop_config.get(shop_code)
        if not shop_info:
            logger.error(f"Configuration manquante pour le magasin {shop_code}")
            return False
        
        base_url = shop_info['url']
        shop_name = shop_info['name']
        
        logger.info(f"==================================================")
        logger.info(f"EXTRACTION RECEPTION MAGASIN {shop_code}")
        logger.info(f"==================================================")
        logger.info(f"URL serveur: {base_url}")
        logger.info(f"Nom magasin: {shop_name}")
        
        # Test de connexion
        if not self.test_api_connection(base_url):
            logger.error(f"‚ùå Impossible de se connecter au serveur {base_url}")
            return False
        
        # R√©cup√©rer les informations du magasin
        logger.info(f"R√©cup√©ration des informations du magasin {shop_code}...")
        shop_data = self.get_shop_info(base_url, shop_code)
        if not shop_data:
            logger.error(f"‚ùå Impossible de r√©cup√©rer les informations du magasin {shop_code}")
            return False
        
        shop_id = shop_data.get('id')
        if not shop_id:
            logger.error(f"‚ùå ID du magasin non trouv√©")
            return False
        
        # R√©cup√©rer les donn√©es
        logger.info(f"R√©cup√©ration des donn√©es pour le magasin {shop_code}...")
        data = self.get_data(base_url, shop_id)
        
        if not data:
            logger.warning(f"‚ö†Ô∏è Aucune donn√©e trouv√©e pour le magasin {shop_code}")
            return True
        
        logger.info(f"‚úÖ {len(data)} √©l√©ments r√©cup√©r√©s au total pour le magasin {shop_code}")
        
        # Exporter vers CSV
        logger.info("=" * 60)
        logger.info(f"üíæ EXPORT CSV - MAGASIN {shop_code}")
        logger.info("=" * 60)
        csv_file = self.export_to_csv(data, shop_code, shop_name)
        if csv_file:
            logger.info("=" * 60)
        logger.info(f"‚úÖ MAGASIN {shop_code} TRAIT√â AVEC SUCC√àS")
        logger.info("=" * 60)
        logger.info(f"üìÅ Fichier sur le r√©seau: {csv_file}")
            logger.info(f"üìä Lignes export√©es: {len(data):,}")
        logger.info("=" * 60)
            return True
        else:
            logger.error(f"‚ùå Erreur lors de l'export pour le magasin {shop_code}")
            return False

    def extract_all(self):
        """Extrait les donn√©es pour tous les magasins configur√©s"""
        logger.info("=" * 60)
        logger.info("D√âBUT DE L'EXTRACTION API PROSUMA - RECEPTION")
        logger.info("=" * 60)
        
                # Cr√©er le dossier r√©seau au d√©but
        network_path = self.get_network_path_for_shop("RECEPTION")
        if network_path:
            logger.info(f"‚úÖ Dossier r√©seau cr√©√©: {network_path}")
        else:
            logger.warning("‚ö†Ô∏è Impossible de cr√©er le dossier r√©seau")
        
        successful_shops = 0
        total_shops = len(self.shop_codes)
        failed_shops = []  # Liste des magasins en √©chec avec leur nom
        
        for shop_code in self.shop_codes:
            try:
                if self.extract_shop(shop_code):
                    successful_shops += 1
                else:
                    # Extraction √©chou√©e
                    shop_name = self.shop_config.get(shop_code, {}).get('name', 'Nom inconnu')
                    failed_shops.append((shop_code, shop_name))
            except Exception as e:
                # Erreur lors de l'extraction
                shop_name = self.shop_config.get(shop_code, {}).get('name', 'Nom inconnu')
                failed_shops.append((shop_code, shop_name))
                logger.error(f"‚ùå Erreur lors de l'extraction du magasin {shop_code}: {e}")
        
        # R√©sum√©
        logger.info("=" * 60)
        logger.info("üìäüìäüìä R√âSUM√â FINAL DE L'EXTRACTION üìäüìäüìä")
        logger.info("=" * 60)
        logger.info(f"‚úÖ Magasins trait√©s avec succ√®s: {successful_shops}/{total_shops}")
        logger.info(f"‚ùå Magasins en √©chec: {len(failed_shops)}/{total_shops}")
        
        # Afficher les magasins en erreur s'il y en a
        if failed_shops:
            logger.warning("=" * 60)
            logger.warning("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è EXTRACTION PARTIELLEMENT R√âUSSIE ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
            logger.warning("=" * 60)
            logger.warning("")
            logger.warning("üìãüìãüìã LISTE DES MAGASINS EN √âCHEC üìãüìãüìã")
            logger.warning("=" * 60)
            for shop_code, shop_name in failed_shops:
                logger.warning(f"   ‚ùå Code magasin: {shop_code} - Nom: {shop_name}")
            logger.warning("=" * 60)
            logger.warning("")
        elif successful_shops == total_shops:
            logger.info("=" * 60)
            logger.info("‚úÖ‚úÖ‚úÖ EXTRACTION COMPL√àTEMENT R√âUSSIE ‚úÖ‚úÖ‚úÖ")
            logger.info("=" * 60)
        else:
            logger.error("=" * 60)
            logger.error("‚ùå‚ùå‚ùå AUCUNE EXTRACTION R√âUSSIE ‚ùå‚ùå‚ùå")
            logger.error("=" * 60)

def main():
    """Fonction principale"""
    try:
        extractor = ProsumaAPIReceptionExtractor()
        extractor.extract_all()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")

if __name__ == "__main__":
    main()
