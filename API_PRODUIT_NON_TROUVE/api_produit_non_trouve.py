#!/usr/bin/env python3
"""
Extracteur API Prosuma RPOS - Produits non trouv√©s (Event Line)
R√©cup√®re les √©v√©nements de produits non trouv√©s via l'API event_line
"""

import requests
import os
import csv
import json
import logging
import platform
from datetime import datetime, timedelta
from dotenv import load_dotenv
import urllib3
import sys

# Ajouter le r√©pertoire parent au path pour importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import load_shop_config, build_network_path, create_network_folder, SafeStreamHandler

# D√©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class ProsumaAPIProduitNonTrouveExtractor:
    def __init__(self):
        """Initialise l'extracteur avec la configuration"""
        # D√©terminer le chemin racine du projet
        current_file = os.path.abspath(__file__)
        project_root = os.path.dirname(os.path.dirname(current_file))
        
        # Essayer de charger le fichier config.env depuis la racine du projet
        config_path = os.path.join(project_root, 'config.env')
        
        # V√©rifier si le fichier existe
        if not os.path.exists(config_path):
            # Essayer aussi depuis le r√©pertoire courant du script
            script_dir = os.path.dirname(current_file)
            local_config = os.path.join(script_dir, 'config.env')
            if os.path.exists(local_config):
                config_path = local_config
            else:
                raise FileNotFoundError(
                    f"Fichier config.env introuvable. Cherch√© dans:\n"
                    f"  - {config_path}\n"
                    f"  - {local_config}\n"
                    f"Veuillez cr√©er le fichier config.env √† la racine du projet."
                )
        
        # Charger les variables d'environnement
        load_dotenv(config_path)
        print(f"üìÅ Fichier config.env charg√© depuis: {config_path}")
        
        self.username = os.getenv('PROSUMA_USER')
        self.password = os.getenv('PROSUMA_PASSWORD')
        
        if not self.username or not self.password:
            raise ValueError(
                f"PROSUMA_USER et PROSUMA_PASSWORD doivent √™tre configur√©s dans config.env\n"
                f"Fichier utilis√©: {config_path}\n"
                f"PROSUMA_USER trouv√©: {'Oui' if self.username else 'Non'}\n"
                f"PROSUMA_PASSWORD trouv√©: {'Oui' if self.password else 'Non'}"
            )
        
        # Configuration du dossier de t√©l√©chargement
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.network_folder_base = os.getenv('DOWNLOAD_FOLDER_BASE', '\\\\10.0.70.169\\\\share\\\\FOFANA')
        
        # Configuration des magasins
        self.shop_config = load_shop_config(os.path.dirname(self.base_dir))
        self.shop_codes = list(self.shop_config.keys())
        
        # Configuration des dates (hier -> aujourd'hui par d√©faut)
        self.setup_dates()
        
        # Configuration du logging sera faite dans setup_logging()
        self.setup_logging()
        
        # Session HTTP
        self.session = requests.Session()
        self.session.auth = (self.username, self.password)
        self.session.verify = False

        print(f"Extracteur API Produits Non Trouv√©s Prosuma initialis√© pour {self.username}")
        print(f"Magasins configur√©s: {self.shop_codes}")
        print(f"P√©riode: {self.start_date.strftime('%Y-%m-%d')} √† {self.end_date.strftime('%Y-%m-%d')}")

    def setup_logging(self):
        """Configure le logging avec fichier sur le r√©seau"""
        log_path = self.get_log_network_path()
        if log_path:
            log_file = os.path.join(log_path, 'prosuma_api_produit_non_trouve.log')
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(log_file, encoding='utf-8'),
                    SafeStreamHandler()
                ]
            )
        else:
            log_file = 'prosuma_api_produit_non_trouve.log'
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(log_file, encoding='utf-8'),
                    SafeStreamHandler()
                ]
            )
        
        # D√©finir les permissions pour permettre √† tous les utilisateurs d'√©crire
        from utils import set_log_file_permissions
        set_log_file_permissions(log_file)
        
        global logger
        logger = logging.getLogger(__name__)

    def setup_dates(self):
        """Configure les dates de filtrage (hier -> aujourd'hui par d√©faut)"""
        # Lire les dates depuis config.env
        date_start_str = os.getenv('DATE_START', '').strip()
        date_end_str = os.getenv('DATE_END', '').strip()
        
        if date_start_str and date_end_str:
            # Utiliser les dates personnalis√©es
            try:
                # Parser les dates et ajouter les heures appropri√©es
                start_date_only = datetime.strptime(date_start_str, '%Y-%m-%d')
                end_date_only = datetime.strptime(date_end_str, '%Y-%m-%d')
                
                # Ajouter 00:00:00 pour la date de d√©but et 23:59:59 pour la date de fin
                self.start_date = start_date_only.replace(hour=0, minute=0, second=0, microsecond=0)
                self.end_date = end_date_only.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                print(f"Dates personnalis√©es: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
            except ValueError:
                print("Format de date invalide, utilisation des dates par d√©faut")
                self.setup_default_dates()
        else:
            # Utiliser les dates par d√©faut (hier -> aujourd'hui)
            self.setup_default_dates()
    
    def setup_default_dates(self):
        """Configure les dates par d√©faut (hier -> aujourd'hui)"""
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        
        # Ajouter les heures appropri√©es
        self.start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
        self.end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        print(f"Dates par d√©faut: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")

    def get_log_network_path(self):
        """Retourne le chemin r√©seau pour les logs"""
        if not self.network_folder_base:
            return None
        # Chemin: \\\\10.0.70.169\\share\\FOFANA\\Etats Natacha\\SCRIPT\\LOG
        base = self.network_folder_base.replace('/', '\\\\')
        if base.endswith('\\\\'):
            base = base[:-1]
        log_path = f"{base}\\\\Etats Natacha\\\\SCRIPT\\\\LOG"
        if create_network_folder(log_path):
            return log_path
        return None

    def test_api_connection(self, base_url):
        """Teste la connexion √† l'API"""
        try:
            test_url = f"{base_url}/api/user/"
            response = self.session.get(test_url, timeout=30)
            if response.status_code == 200:
                logger.info(f"‚úÖ Connexion API r√©ussie: {base_url}")
                return True
            else:
                logger.error(f"‚ùå Erreur de connexion API {base_url}: {response.status_code} {response.reason}")
                if response.status_code == 401:
                    logger.error(f"‚ùå Erreur d'authentification - V√©rifiez PROSUMA_USER et PROSUMA_PASSWORD dans config.env")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erreur de connexion API {base_url}: {e}")
            return False

    def get_shop_info(self, base_url, shop_code):
        """R√©cup√®re les informations du magasin"""
        try:
            url = f"{base_url}/api/shop/"
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                # G√©rer la structure pagin√©e
                if isinstance(data, dict) and 'results' in data:
                    shops = data['results']
                elif isinstance(data, list):
                    shops = data
                else:
                    logger.error(f"‚ùå Format de r√©ponse invalide: {type(data)}")
                    return None
                
                for shop in shops:
                    if str(shop.get('reference')) == str(shop_code):
                        logger.info(f"‚úÖ Magasin {shop_code} trouv√©: {shop.get('name', 'N/A')}")
                        return shop
                
                logger.warning(f"‚ö†Ô∏è Magasin {shop_code} non trouv√© dans la liste")
                return None
            else:
                logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des magasins: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des informations du magasin: {e}")
            return None


    def display_extraction_frame(self, shop_code, shop_name, total_items, total_pages, period):
        """Affiche un cadre avec les d√©tails de l'extraction"""
        logger.info("‚îå" + "‚îÄ" * 78 + "‚îê")
        logger.info("‚îÇ" + " " * 78 + "‚îÇ")
        logger.info(f"‚îÇ{'üì¶ EXTRACTION PRODUITS NON TROUV√âS':^78}‚îÇ")
        logger.info("‚îÇ" + " " * 78 + "‚îÇ")
        line1 = f"üè™ Magasin: {shop_name} ({shop_code})"
        logger.info("‚îÇ  " + line1 + " " * (76 - len(line1)) + "‚îÇ")
        line2 = f"üìÖ P√©riode: {period}"
        logger.info("‚îÇ  " + line2 + " " * (76 - len(line2)) + "‚îÇ")
        line3 = f"üìä Total √©l√©ments: {total_items:,}"
        logger.info("‚îÇ  " + line3 + " " * (76 - len(line3)) + "‚îÇ")
        line4 = f"üìÑ Pages √† traiter: {total_pages}"
        logger.info("‚îÇ  " + line4 + " " * (76 - len(line4)) + "‚îÇ")
        logger.info("‚îÇ" + " " * 78 + "‚îÇ")
        logger.info("‚îî" + "‚îÄ" * 78 + "‚îò")

    
    def count_total_records(self, base_url, shop_id, page_size=1000):
        """Compte le nombre total d'enregistrements disponibles"""
        try:
            url = f"{base_url}/api/event_line/product_not_found"
            params = {
                'shop': shop_id,  # Ajouter le param√®tre shop pour filtrer par magasin
                'page_size': page_size,
                'page': 1
            }
            
            # Ajouter les param√®tres de date si disponibles (format ISO avec timezone)
            if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
                params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
            
            logger.info(f"üîç URL appel√©e: {url}")
            logger.info(f"üîç Param√®tres: {params}")
            response = self.session.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                # Afficher un aper√ßu de la r√©ponse pour le d√©bogage
                logger.debug(f"üìã Structure de la r√©ponse: {list(data.keys()) if isinstance(data, dict) else 'Liste'}")
                
                if isinstance(data, dict) and 'results' in data:
                    # Si c'est une r√©ponse pagin√©e
                    results_count = len(data.get('results', []))
                    total_count = data.get('count', 0)
                    
                    # Si count est 0 mais qu'il y a des r√©sultats, utiliser le nombre de r√©sultats
                    if total_count == 0 and results_count > 0:
                        logger.warning(f"‚ö†Ô∏è L'API retourne count=0 mais {results_count} r√©sultats - utilisation du nombre de r√©sultats")
                        total_count = results_count
                    
                    logger.info(f"‚úÖ Comptage r√©ussi: {total_count} enregistrements (page 1: {results_count} r√©sultats)")
                    return total_count
                elif isinstance(data, list):
                    # Si c'est directement une liste
                    total_count = len(data)
                    logger.info(f"‚úÖ Comptage r√©ussi: {total_count} enregistrements (liste directe)")
                    return total_count
                else:
                    total_count = data.get('count', 0)
                    logger.info(f"‚úÖ Comptage r√©ussi: {total_count} enregistrements")
                    return total_count
            else:
                logger.error(f"‚ùå Erreur lors du comptage: {response.status_code}")
                logger.error(f"‚ùå R√©ponse: {response.text[:500]}")
                # Essayer sans le param√®tre shop si l'erreur est 400
                if response.status_code == 400:
                    logger.info("üîÑ Tentative sans le param√®tre shop...")
                    params_without_shop = {k: v for k, v in params.items() if k != 'shop'}
                    response2 = self.session.get(url, params=params_without_shop, timeout=30)
                    if response2.status_code == 200:
                        data = response2.json()
                        total_count = data.get('count', 0)
                        logger.info(f"‚úÖ Comptage r√©ussi (sans shop): {total_count} enregistrements")
                        return total_count
                return 0
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du comptage: {e}")
            return 0

    def get_event_lines(self, base_url, shop_id, page_size=1000):
        """R√©cup√®re les donn√©es avec pagination compl√®te"""
        # D'abord, compter le nombre total d'enregistrements
        logger.info("üîç Comptage du nombre total d'enregistrements...")
        total_records = self.count_total_records(base_url, shop_id, page_size)
        
        # Si total_records est 0, on fait quand m√™me une requ√™te pour v√©rifier s'il y a des r√©sultats
        # (car l'API peut retourner count=0 mais avoir des r√©sultats)
        if total_records == 0:
            logger.info("üîç V√©rification directe des r√©sultats (count=0 mais peut-√™tre des r√©sultats)...")
            # Faire une requ√™te pour voir s'il y a vraiment des r√©sultats
            url = f"{base_url}/api/event_line/product_not_found"
            params = {
                'shop': shop_id,
                'page_size': 100,
                'page': 1
            }
            if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
                params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
            
            try:
                response = self.session.get(url, params=params, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    if isinstance(data, dict) and 'results' in data:
                        results = data.get('results', [])
                        if len(results) > 0:
                            logger.info(f"‚úÖ {len(results)} r√©sultats trouv√©s malgr√© count=0 - extraction avec pagination")
                            # Estimer le total en fonction du nombre de r√©sultats et de la page_size
                            # Si on a 100 r√©sultats sur la premi√®re page avec page_size=100, il peut y en avoir plus
                            total_records = max(len(results), 1000)  # Estimation conservatrice
                            logger.info(f"üìä Estimation: au moins {len(results)} r√©sultats, extraction avec pagination jusqu'√† {total_records}")
                        else:
                            logger.warning("‚ö†Ô∏è Aucun enregistrement trouv√©")
                            return []
                    elif isinstance(data, list) and len(data) > 0:
                        logger.info(f"‚úÖ {len(data)} r√©sultats trouv√©s (liste directe) - extraction des donn√©es")
                        total_records = len(data)
                    else:
                        logger.warning("‚ö†Ô∏è Aucun enregistrement trouv√©")
                        return []
                else:
                    logger.warning("‚ö†Ô∏è Aucun enregistrement trouv√©")
                    return []
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la v√©rification: {e}")
                import traceback
                logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
                return []
        
        # Afficher le cadre avec le nombre total
        logger.info("=" * 60)
        logger.info(f"üìä INFORMATIONS D'EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"üìä Total enregistrements disponibles: {total_records:,}")
        logger.info(f"üìÖ P√©riode: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"üè™ Magasin: {shop_id}")
        logger.info("=" * 60)
        
        all_data = []
        page = 1
        total_pages = (total_records + page_size - 1) // page_size  # Calcul du nombre total de pages
        
        try:
            while page <= total_pages:
                url = f"{base_url}/api/event_line/product_not_found"
                params = {
                    'shop': shop_id,  # Ajouter le param√®tre shop pour filtrer par magasin
                    'page_size': page_size,
                    'page': page
                }
                
                # Ajouter les param√®tres de date si disponibles (format ISO avec timezone)
                if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                    params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
                    params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S+00:00')
                
                # Afficher la progression
                progress_percent = (page - 1) * 100 // total_pages if total_pages > 0 else 0
                logger.info(f"üìÑ R√©cup√©ration page {page}/{total_pages} ({progress_percent}%) - {len(all_data):,}/{total_records:,} enregistrements...")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('results', [])
                    
                    if not items:
                        logger.info(f"  ‚úÖ Derni√®re page atteinte (page {page}) - Aucun enregistrement retourn√©")
                        break
                    
                    all_data.extend(items)
                    logger.info(f"  ‚úÖ Page {page}: {len(items)} √©l√©ments r√©cup√©r√©s (total: {len(all_data):,}/{total_records:,})")
                    
                    # Si on est √† la derni√®re page calcul√©e, on arr√™te
                    if page >= total_pages:
                        logger.info(f"  ‚úÖ Derni√®re page calcul√©e atteinte (page {page}/{total_pages})")
                        # Si on a une estimation (total_records > 1000), continuer jusqu'√† ce qu'on n'ait plus de r√©sultats
                        if total_records > 1000 and len(items) > 0:
                            logger.info(f"  üîÑ Continuation de la pagination (estimation)...")
                            page += 1
                            continue
                        break
                    
                    # Continuer avec la page suivante
                    page += 1
                else:
                    logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {response.status_code}")
                    logger.error(f"‚ùå URL: {url}")
                    logger.error(f"‚ùå Param√®tres: {params}")
                    logger.error(f"‚ùå R√©ponse: {response.text[:500]}")
                    # Continuer avec la page suivante en cas d'erreur temporaire
                    if response.status_code == 500 or response.status_code == 503:
                        logger.warning(f"‚ö†Ô∏è Erreur serveur, tentative de continuer...")
                        page += 1
                        continue
                    break
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {e}")
            import traceback
            logger.error(f"‚ùå Traceback complet:\n{traceback.format_exc()}")
        
        # Afficher le r√©sum√© final
        logger.info("=" * 60)
        logger.info(f"‚úÖ R√âSUM√â EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"üìä Enregistrements trouv√©s: {total_records:,}")
        logger.info(f"üì• Enregistrements extraits: {len(all_data):,}")
        logger.info(f"üìà Taux de r√©ussite: {(len(all_data)/total_records*100):.1f}%" if total_records > 0 else "üìà Taux de r√©ussite: 0%")
        logger.info("=" * 60)
        
        return all_data

    def _flatten_value(self, value, max_length=1000):
        """Convertit une valeur complexe en cha√Æne pour le CSV"""
        if value is None:
            return ''
        elif isinstance(value, bool):
            return 'Oui' if value else 'Non'
        elif isinstance(value, (int, float)):
            return str(value)
        elif isinstance(value, str):
            # Nettoyer les retours √† la ligne et autres caract√®res probl√©matiques
            return value.replace('\n', ' ').replace('\r', ' ').strip()
        elif isinstance(value, dict):
            # Convertir le dictionnaire en JSON compact
            try:
                json_str = json.dumps(value, ensure_ascii=False, separators=(',', ':'))
                if len(json_str) > max_length:
                    return json_str[:max_length] + '...'
                return json_str
            except:
                return str(value)
        elif isinstance(value, list):
            # Si c'est une liste de dictionnaires, simplifier
            if value and isinstance(value[0], dict):
                try:
                    # Prendre seulement les cl√©s principales
                    simplified = []
                    for item in value[:5]:  # Limiter √† 5 √©l√©ments
                        if isinstance(item, dict):
                            simplified.append({k: v for k, v in list(item.items())[:3]})
                    json_str = json.dumps(simplified, ensure_ascii=False, separators=(',', ':'))
                    if len(json_str) > max_length:
                        return json_str[:max_length] + '...'
                    return json_str
                except:
                    return str(value)
            else:
                return ', '.join(str(v) for v in value[:10])  # Limiter √† 10 √©l√©ments
        else:
            return str(value)

    def _get_all_fields_from_events(self, events):
        """D√©tecte dynamiquement tous les champs disponibles dans les √©v√©nements"""
        all_fields = set()
        
        for event in events:
            if isinstance(event, dict):
                all_fields.update(event.keys())
        
        # Trier et retourner la liste
        field_list = sorted(list(all_fields))
        
        # Ajouter shop_code et shop_name en premier
        important_fields = ['shop_code', 'shop_name']
        for field in important_fields:
            if field in field_list:
                field_list.remove(field)
        
        return important_fields + field_list

    def export_to_csv(self, events, shop_code, shop_name):
        """Exporte les √©v√©nements vers un fichier CSV directement dans le dossier ASTEN"""
        if not events:
            logger.warning(f"Aucun √©v√©nement √† exporter pour le magasin {shop_code}")
            return None
        
        # Chemin direct vers le dossier ASTEN (racine, pas de dossier par magasin)
        asten_extraction_path = r"\\10.0.70.169\share\ASTEN\GESTION DES INCONUS MAG\MAG ASTEN\EXTRACTIONS\PRODUIT NON TROUVES"
        
        # Cr√©er le dossier s'il n'existe pas
        if not os.path.exists(asten_extraction_path):
            try:
                os.makedirs(asten_extraction_path)
                logger.info(f"üìÅ Dossier ASTEN cr√©√©: {asten_extraction_path}")
            except Exception as e:
                logger.error(f"‚ùå Impossible de cr√©er le dossier ASTEN: {e}")
                return None
        
        # Cr√©er le nom du fichier
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'export_produit_non_trouve_{shop_code}_{timestamp}.csv'
        final_filepath = os.path.join(asten_extraction_path, filename)
        
        # D√©tecter dynamiquement tous les champs disponibles
        fieldnames = self._get_all_fields_from_events(events)
        
        logger.info(f"üìã Champs d√©tect√©s dans l'API: {len(fieldnames)} champs")
        logger.info(f"   Champs: {', '.join(fieldnames[:10])}{'...' if len(fieldnames) > 10 else ''}")
        
        try:
            # Cr√©er le fichier CSV DIRECTEMENT sur le r√©seau (pas de fichier local)
            with open(final_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')
                writer.writeheader()
                
                for event in events:
                    # Pr√©parer les donn√©es pour l'export avec tous les champs d√©tect√©s
                    row = {}
                    for field in fieldnames:
                        if field == 'shop_code':
                            row[field] = shop_code
                        elif field == 'shop_name':
                            row[field] = shop_name
                        else:
                            # R√©cup√©rer la valeur et la formater
                            value = event.get(field, '')
                            row[field] = self._flatten_value(value)
                    
                    writer.writerow(row)
            
            # V√©rifier que le fichier a bien √©t√© cr√©√©
            if os.path.exists(final_filepath):
                file_size = os.path.getsize(final_filepath)
                logger.info(f"‚úÖ‚úÖ‚úÖ FICHIER CR√â√â DIRECTEMENT SUR LE R√âSEAU ASTEN ‚úÖ‚úÖ‚úÖ")
                logger.info(f"   üìÅ Chemin: {final_filepath}")
                logger.info(f"   üìä {len(events)} √©v√©nements export√©s")
                logger.info(f"   üìä Taille: {file_size:,} octets")
                logger.info(f"   üìã {len(fieldnames)} colonnes par √©v√©nement")
                return final_filepath
            else:
                logger.error(f"‚ùå Le fichier n'existe pas apr√®s cr√©ation: {final_filepath}")
                return None
            
        except PermissionError as e:
            logger.error(f"‚ùå Erreur de permission lors de l'√©criture: {e}")
            logger.error(f"   V√©rifiez les permissions du partage r√©seau")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'export CSV: {e}")
            logger.error(f"   Type: {type(e).__name__}")
            return None
    

    def extract_shop(self, shop_code):
        """Extrait les √©v√©nements pour un magasin sp√©cifique"""
        shop_info = self.shop_config.get(shop_code)
        if not shop_info:
            logger.error(f"Configuration manquante pour le magasin {shop_code}")
            return False
        
        base_url = shop_info['url']
        shop_name = shop_info['name']
        
        logger.info(f"==================================================")
        logger.info(f"EXTRACTION PRODUITS NON TROUV√âS MAGASIN {shop_code}")
        logger.info(f"==================================================")
        logger.info(f"URL serveur: {base_url}")
        logger.info(f"Nom magasin: {shop_name}")
        
        # Test de connexion
        if not self.test_api_connection(base_url):
            logger.error(f"‚ùå Impossible de se connecter au serveur {base_url}")
            logger.warning(f"‚ö†Ô∏è Le magasin {shop_code} ({shop_name}) sera ignor√© et le script continuera avec les autres magasins")
            return False
        
        # R√©cup√©rer les informations du magasin
        logger.info(f"R√©cup√©ration des informations du magasin {shop_code}...")
        shop_data = self.get_shop_info(base_url, shop_code)
        if not shop_data:
            logger.error(f"‚ùå Impossible de r√©cup√©rer les informations du magasin {shop_code}")
            return False
        
        shop_id = shop_data.get('id')
        if not shop_id:
            logger.error(f"‚ùå ID du magasin non trouv√©")
            return False
        
        # R√©cup√©rer les √©v√©nements
        logger.info(f"R√©cup√©ration des √©v√©nements pour le magasin {shop_code}...")
        events = self.get_event_lines(base_url, shop_id)
        
        if not events:
            logger.info(f"‚ÑπÔ∏è Aucun √©v√©nement de produit non trouv√© pour le magasin {shop_code} pour la p√©riode s√©lectionn√©e")
            logger.info(f"   (C'est normal s'il n'y a pas eu de produits non trouv√©s ce jour-l√†)")
            return True
        
        # Exporter vers CSV
        logger.info("=" * 60)
        logger.info(f"üíæ EXPORT CSV - MAGASIN {shop_code}")
        logger.info("=" * 60)
        csv_file = self.export_to_csv(events, shop_code, shop_name)
        if csv_file:
            logger.info("=" * 60)
            logger.info(f"‚úÖ MAGASIN {shop_code} TRAIT√â AVEC SUCC√àS")
            logger.info("=" * 60)
            logger.info(f"üìÅ Fichier sur le r√©seau: {csv_file}")
            logger.info(f"üìä Lignes export√©es: {len(events):,}")
            logger.info("=" * 60)
            return True
        else:
            logger.error(f"‚ùå Erreur lors de l'export pour le magasin {shop_code}")
            return False

    def extract_all(self):
        """Extrait les √©v√©nements pour tous les magasins configur√©s"""
        logger.info("=" * 60)
        logger.info("D√âBUT DE L'EXTRACTION API PROSUMA - PRODUITS NON TROUV√âS")
        logger.info("=" * 60)
        
        # V√©rifier que le dossier ASTEN existe
        asten_extraction_path = r"\\10.0.70.169\share\ASTEN\GESTION DES INCONUS MAG\MAG ASTEN\EXTRACTIONS\PRODUIT NON TROUVES"
        if not os.path.exists(asten_extraction_path):
            try:
                os.makedirs(asten_extraction_path)
                logger.info(f"‚úÖ Dossier ASTEN cr√©√©: {asten_extraction_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier ASTEN: {e}")
        else:
            logger.info(f"‚úÖ Dossier ASTEN v√©rifi√©: {asten_extraction_path}")
        
        successful_shops = 0
        total_shops = len(self.shop_codes)
        failed_shops = []  # Liste des magasins en √©chec avec leur nom
        
        for shop_code in self.shop_codes:
            try:
                shop_info = self.shop_config.get(shop_code, {})
                shop_name = shop_info.get('name', 'Nom inconnu')
                
                if self.extract_shop(shop_code):
                    successful_shops += 1
                else:
                    # Extraction √©chou√©e (connexion, authentification, etc.)
                    failed_shops.append((shop_code, shop_name))
            except Exception as e:
                # Erreur lors de l'extraction
                shop_info = self.shop_config.get(shop_code, {})
                shop_name = shop_info.get('name', 'Nom inconnu')
                failed_shops.append((shop_code, shop_name))
                logger.error(f"‚ùå Erreur lors de l'extraction du magasin {shop_code}: {e}")
        
        # R√©sum√©
        logger.info("=" * 60)
        logger.info("R√âSUM√â DE L'EXTRACTION")
        logger.info("=" * 60)
        logger.info(f"‚úÖ Magasins trait√©s avec succ√®s: {successful_shops}/{total_shops}")
        logger.info(f"‚ùå Magasins en √©chec: {len(failed_shops)}/{total_shops}")
        
        # Afficher les magasins en erreur s'il y en a
        if failed_shops:
            logger.warning("=" * 60)
            logger.warning("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è EXTRACTION PARTIELLEMENT R√âUSSIE ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
            logger.warning("=" * 60)
            logger.warning("")
            logger.warning("üìãüìãüìã LISTE DES MAGASINS EN √âCHEC üìãüìãüìã")
            logger.warning("=" * 60)
            for shop_code, shop_name in failed_shops:
                logger.warning(f"   ‚ùå Code magasin: {shop_code} - Nom: {shop_name}")
            logger.warning("=" * 60)
            logger.warning("")
        elif successful_shops == total_shops:
            logger.info("=" * 60)
            logger.info("‚úÖ‚úÖ‚úÖ EXTRACTION COMPL√àTEMENT R√âUSSIE ‚úÖ‚úÖ‚úÖ")
            logger.info("=" * 60)
        else:
            logger.error("=" * 60)
            logger.error("‚ùå‚ùå‚ùå AUCUNE EXTRACTION R√âUSSIE ‚ùå‚ùå‚ùå")
            logger.error("=" * 60)

def main():
    """Fonction principale"""
    try:
        extractor = ProsumaAPIProduitNonTrouveExtractor()
        extractor.extract_all()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")

if __name__ == "__main__":
    main()