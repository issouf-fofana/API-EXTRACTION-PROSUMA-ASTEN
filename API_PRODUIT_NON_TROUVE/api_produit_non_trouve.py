#!/usr/bin/env python3
"""
Extracteur API Prosuma RPOS - Produits non trouvÃ©s (Event Line)
RÃ©cupÃ¨re les Ã©vÃ©nements de produits non trouvÃ©s via l'API event_line
"""

import requests
import os
import csv
import json
import logging
import shutil
import platform
from datetime import datetime, timedelta
from dotenv import load_dotenv
import urllib3
import sys

# Ajouter le rÃ©pertoire parent au path pour importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import load_shop_config, build_network_path, create_network_folder, SafeStreamHandler

# DÃ©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class ProsumaAPIProduitNonTrouveExtractor:
    def __init__(self):
        """Initialise l'extracteur avec la configuration"""
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        load_dotenv(os.path.join(project_root, 'config.env'))
        
        self.username = os.getenv('PROSUMA_USER')
        self.password = os.getenv('PROSUMA_PASSWORD')
        
        if not self.username or not self.password:
            raise ValueError("PROSUMA_USER et PROSUMA_PASSWORD doivent Ãªtre configurÃ©s dans config.env")
        
        # Configuration du dossier de tÃ©lÃ©chargement
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.network_folder_base = os.getenv('DOWNLOAD_FOLDER_BASE', '\\\\10.0.70.169\\\\share\\\\FOFANA')
        
        # Configuration des magasins
        self.shop_config = load_shop_config(os.path.dirname(self.base_dir))
        self.shop_codes = list(self.shop_config.keys())
        
        # Configuration des dates (hier -> aujourd'hui par dÃ©faut)
        self.setup_dates()
        
        # Configuration du logging sera faite dans setup_logging()
        self.setup_logging()
        
        # Session HTTP
        self.session = requests.Session()
        self.session.auth = (self.username, self.password)
        self.session.verify = False

        print(f"Extracteur API Produits Non TrouvÃ©s Prosuma initialisÃ© pour {self.username}")
        print(f"Magasins configurÃ©s: {self.shop_codes}")
        print(f"PÃ©riode: {self.start_date.strftime('%Y-%m-%d')} Ã  {self.end_date.strftime('%Y-%m-%d')}")

    def setup_logging(self):
        """Configure le logging avec fichier sur le rÃ©seau"""
        log_path = self.get_log_network_path()
        if log_path:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(os.path.join(log_path, 'prosuma_api_produit_non_trouve.log')),
                    SafeStreamHandler()
                ]
            )
        else:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler('prosuma_api_produit_non_trouve.log'),
                    SafeStreamHandler()
                ]
            )
        
        global logger
        logger = logging.getLogger(__name__)

    def setup_dates(self):
        """Configure les dates de filtrage (hier -> aujourd'hui par dÃ©faut)"""
        # Lire les dates depuis config.env
        date_start_str = os.getenv('DATE_START', '').strip()
        date_end_str = os.getenv('DATE_END', '').strip()
        
        if date_start_str and date_end_str:
            # Utiliser les dates personnalisÃ©es
            try:
                # Parser les dates et ajouter les heures appropriÃ©es
                start_date_only = datetime.strptime(date_start_str, '%Y-%m-%d')
                end_date_only = datetime.strptime(date_end_str, '%Y-%m-%d')
                
                # Ajouter 00:00:00 pour la date de dÃ©but et 23:59:59 pour la date de fin
                self.start_date = start_date_only.replace(hour=0, minute=0, second=0, microsecond=0)
                self.end_date = end_date_only.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                print(f"Dates personnalisÃ©es: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} Ã  {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
            except ValueError:
                print("Format de date invalide, utilisation des dates par dÃ©faut")
                self.setup_default_dates()
        else:
            # Utiliser les dates par dÃ©faut (hier -> aujourd'hui)
            self.setup_default_dates()
    
    def setup_default_dates(self):
        """Configure les dates par dÃ©faut (hier -> aujourd'hui)"""
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        
        # Ajouter les heures appropriÃ©es
        self.start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
        self.end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        print(f"Dates par dÃ©faut: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} Ã  {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")

    def get_network_path_for_shop(self, shop_code):
        """Retourne le chemin rÃ©seau pour un magasin spÃ©cifique"""
        network_path = build_network_path(self.network_folder_base, "PRODUIT_NON_TROUVE")
        if create_network_folder(network_path):
            return network_path
        return None
        
    def get_log_network_path(self):
        """Retourne le chemin rÃ©seau pour les logs"""
        if not self.network_folder_base:
            return None
        # Chemin: \\\\10.0.70.169\\share\\FOFANA\\Etats Natacha\\SCRIPT\\LOG
        base = self.network_folder_base.replace('/', '\\\\')
        if base.endswith('\\\\'):
            base = base[:-1]
        log_path = f"{base}\\\\Etats Natacha\\\\SCRIPT\\\\LOG"
        if create_network_folder(log_path):
            return log_path
        return None

    def test_api_connection(self, base_url):
        """Teste la connexion Ã  l'API"""
        try:
            test_url = f"{base_url}/api/user/"
            response = self.session.get(test_url, timeout=10)
            if response.status_code == 200:
                logger.info(f"âœ… Connexion API rÃ©ussie: {base_url}")
                return True
            else:
                logger.error(f"âŒ Erreur de connexion API {base_url}: {response.status_code} {response.reason}")
                return False
        except Exception as e:
            logger.error(f"âŒ Erreur de connexion API {base_url}: {e}")
            return False

    def get_shop_info(self, base_url, shop_code):
        """RÃ©cupÃ¨re les informations du magasin"""
        try:
            url = f"{base_url}/api/shop/"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # GÃ©rer la structure paginÃ©e
                if isinstance(data, dict) and 'results' in data:
                    shops = data['results']
                elif isinstance(data, list):
                    shops = data
                else:
                    logger.error(f"âŒ Format de rÃ©ponse invalide: {type(data)}")
                    return None
                
                for shop in shops:
                    if str(shop.get('reference')) == str(shop_code):
                        logger.info(f"âœ… Magasin {shop_code} trouvÃ©: {shop.get('name', 'N/A')}")
                        return shop
                
                logger.warning(f"âš ï¸ Magasin {shop_code} non trouvÃ© dans la liste")
                return None
            else:
                logger.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration des magasins: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration des informations du magasin: {e}")
            return None


    def display_extraction_frame(self, shop_code, shop_name, total_items, total_pages, period):
        """Affiche un cadre avec les dÃ©tails de l'extraction"""
        logger.info("â”Œ" + "â”€" * 78 + "â”")
        logger.info("â”‚" + " " * 78 + "â”‚")
        logger.info(f"â”‚{'ğŸ“¦ EXTRACTION PRODUITS NON TROUVÃ‰S':^78}â”‚")
        logger.info("â”‚" + " " * 78 + "â”‚")
        line1 = f"ğŸª Magasin: {shop_name} ({shop_code})"
        logger.info("â”‚  " + line1 + " " * (76 - len(line1)) + "â”‚")
        line2 = f"ğŸ“… PÃ©riode: {period}"
        logger.info("â”‚  " + line2 + " " * (76 - len(line2)) + "â”‚")
        line3 = f"ğŸ“Š Total Ã©lÃ©ments: {total_items:,}"
        logger.info("â”‚  " + line3 + " " * (76 - len(line3)) + "â”‚")
        line4 = f"ğŸ“„ Pages Ã  traiter: {total_pages}"
        logger.info("â”‚  " + line4 + " " * (76 - len(line4)) + "â”‚")
        logger.info("â”‚" + " " * 78 + "â”‚")
        logger.info("â””" + "â”€" * 78 + "â”˜")

    
    def count_total_records(self, base_url, shop_id, page_size=1000):
        """Compte le nombre total d'enregistrements disponibles"""
        try:
            url = f"{base_url}/api/product/"
            params = {
                'shop': shop_id,
                'page_size': page_size,
                'page': 1
            }
            
            # Ajouter les paramÃ¨tres de date si disponibles
            if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S')
                params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S')
            
            response = self.session.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                total_count = data.get('count', 0)
                return total_count
            else:
                logger.error(f"âŒ Erreur lors du comptage: {response.status_code}")
                return 0
                
        except Exception as e:
            logger.error(f"âŒ Erreur lors du comptage: {e}")
            return 0

    def get_event_lines(self, base_url, shop_id, page_size=1000):
        """RÃ©cupÃ¨re les donnÃ©es avec pagination complÃ¨te"""
        # D'abord, compter le nombre total d'enregistrements
        logger.info("ğŸ” Comptage du nombre total d'enregistrements...")
        total_records = self.count_total_records(base_url, shop_id, page_size)
        
        if total_records == 0:
            logger.warning("âš ï¸ Aucun enregistrement trouvÃ©")
            return []
        
        # Afficher le cadre avec le nombre total
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š INFORMATIONS D'EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š Total enregistrements disponibles: {total_records:,}")
        logger.info(f"ğŸ“… PÃ©riode: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} Ã  {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ğŸª Magasin: {shop_id}")
        logger.info("=" * 60)
        
        all_data = []
        page = 1
        total_pages = (total_records + page_size - 1) // page_size  # Calcul du nombre total de pages
        
        try:
            while page <= total_pages:
                url = f"{base_url}/api/product/"
                params = {
                    'shop': shop_id,
                    'page_size': page_size,
                    'page': page
                }
                
                # Ajouter les paramÃ¨tres de date si disponibles
                if hasattr(self, 'start_date') and hasattr(self, 'end_date'):
                    params['date_0'] = self.start_date.strftime('%Y-%m-%dT%H:%M:%S')
                    params['date_1'] = self.end_date.strftime('%Y-%m-%dT%H:%M:%S')
                
                # Afficher la progression
                progress_percent = (page - 1) * 100 // total_pages if total_pages > 0 else 0
                logger.info(f"ğŸ“„ RÃ©cupÃ©ration page {page}/{total_pages} ({progress_percent}%) - {len(all_data):,}/{total_records:,} enregistrements...")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('results', [])
                    
                    if not items:
                        logger.info(f"  âœ… DerniÃ¨re page atteinte (page {page}) - Aucun enregistrement retournÃ©")
                        break
                    
                    all_data.extend(items)
                    logger.info(f"  âœ… Page {page}: {len(items)} Ã©lÃ©ments rÃ©cupÃ©rÃ©s (total: {len(all_data):,}/{total_records:,})")
                    
                    # VÃ©rifier si on a rÃ©cupÃ©rÃ© tous les enregistrements ou si on est Ã  la derniÃ¨re page
                    if len(all_data) >= total_records:
                        logger.info(f"  âœ… Tous les enregistrements rÃ©cupÃ©rÃ©s (page {page}/{total_pages})")
                        break
                    
                    # Si on est Ã  la derniÃ¨re page calculÃ©e, on arrÃªte
                    if page >= total_pages:
                        logger.info(f"  âœ… DerniÃ¨re page atteinte (page {page}/{total_pages})")
                        break
                    
                    # Continuer avec la page suivante
                    page += 1
                else:
                    logger.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration des donnÃ©es: {response.status_code}")
                    # Continuer avec la page suivante en cas d'erreur temporaire
                    if response.status_code == 500 or response.status_code == 503:
                        logger.warning(f"âš ï¸ Erreur serveur, tentative de continuer...")
                        page += 1
                        continue
                    break
                    
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration des donnÃ©es: {e}")
        
        # Afficher le rÃ©sumÃ© final
        logger.info("=" * 60)
        logger.info(f"âœ… RÃ‰SUMÃ‰ EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š Enregistrements trouvÃ©s: {total_records:,}")
        logger.info(f"ğŸ“¥ Enregistrements extraits: {len(all_data):,}")
        logger.info(f"ğŸ“ˆ Taux de rÃ©ussite: {(len(all_data)/total_records*100):.1f}%" if total_records > 0 else "ğŸ“ˆ Taux de rÃ©ussite: 0%")
        logger.info("=" * 60)
        
        return all_data

    def export_to_csv(self, events, shop_code, shop_name):
        """Exporte les Ã©vÃ©nements vers un fichier CSV"""
        if not events:
            logger.warning(f"Aucun Ã©vÃ©nement Ã  exporter pour le magasin {shop_code}")
            return None
        
        # CrÃ©er le dossier rÃ©seau
        network_path = self.get_network_path_for_shop(shop_code)
        if not network_path:
            logger.error(f"Impossible de crÃ©er le dossier rÃ©seau pour le magasin {shop_code}")
            return None
        
        # CrÃ©er un fichier temporaire local
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'export_produit_non_trouve_{shop_code}_{timestamp}.csv'
        local_filepath = os.path.join(self.base_dir, filename)
        
        # En-tÃªtes CSV selon les vraies colonnes de l'API product_not_found
        fieldnames = [
            'id', 'date', 'term', 'receipt__nb', 'receipt__pos__code',
            'receipt__cashier__code', 'receipt__cashier__id', 'receipt__id',
            'shop_code', 'shop_name'
        ]
        
        try:
            # CrÃ©er le fichier CSV local
            with open(local_filepath, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')
                writer.writeheader()
                
                for event in events:
                    # PrÃ©parer les donnÃ©es pour l'export selon les vraies colonnes
                    row = {
                        'id': event.get('id', ''),
                        'date': event.get('date', ''),
                        'term': event.get('term', ''),
                        'receipt__nb': event.get('receipt__nb', ''),  # NumÃ©ro du ticket
                        'receipt__pos__code': event.get('receipt__pos__code', ''),  # Code de la caisse
                        'receipt__cashier__code': event.get('receipt__cashier__code', ''),  # Code du caissier
                        'receipt__cashier__id': event.get('receipt__cashier__id', ''),  # ID du caissier
                        'receipt__id': event.get('receipt__id', ''),  # ID du ticket
                        'shop_code': shop_code,
                        'shop_name': shop_name
                    }
                    writer.writerow(row)
            
            logger.info(f"âœ… Fichier CSV crÃ©Ã© localement: {local_filepath}")
            logger.info(f"   {len(events)} Ã©vÃ©nements exportÃ©s")
            logger.info(f"   {len(fieldnames)} colonnes par Ã©vÃ©nement")
            
            # Copier vers le rÃ©seau et supprimer le fichier local
            network_filepath = os.path.join(network_path, filename)
            shutil.copy2(local_filepath, network_filepath)
            logger.info(f"âœ… Fichier copiÃ© sur le rÃ©seau: {network_filepath}")
            
            # Supprimer le fichier local
            os.remove(local_filepath)
            logger.info(f"ğŸ—‘ï¸ Fichier local supprimÃ©")
            
            return network_filepath
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'export CSV: {e}")
            return None

    def extract_shop(self, shop_code):
        """Extrait les Ã©vÃ©nements pour un magasin spÃ©cifique"""
        shop_info = self.shop_config.get(shop_code)
        if not shop_info:
            logger.error(f"Configuration manquante pour le magasin {shop_code}")
            return False
        
        base_url = shop_info['url']
        shop_name = shop_info['name']
        
        logger.info(f"==================================================")
        logger.info(f"EXTRACTION PRODUITS NON TROUVÃ‰S MAGASIN {shop_code}")
        logger.info(f"==================================================")
        logger.info(f"URL serveur: {base_url}")
        logger.info(f"Nom magasin: {shop_name}")
        
        # Test de connexion
        if not self.test_api_connection(base_url):
            logger.error(f"âŒ Impossible de se connecter au serveur {base_url}")
            return False
        
        # RÃ©cupÃ©rer les informations du magasin
        logger.info(f"RÃ©cupÃ©ration des informations du magasin {shop_code}...")
        shop_data = self.get_shop_info(base_url, shop_code)
        if not shop_data:
            logger.error(f"âŒ Impossible de rÃ©cupÃ©rer les informations du magasin {shop_code}")
            return False
        
        shop_id = shop_data.get('id')
        if not shop_id:
            logger.error(f"âŒ ID du magasin non trouvÃ©")
            return False
        
        # RÃ©cupÃ©rer les Ã©vÃ©nements
        logger.info(f"RÃ©cupÃ©ration des Ã©vÃ©nements pour le magasin {shop_code}...")
        events = self.get_event_lines(base_url, shop_id)
        
        if not events:
            logger.warning(f"âš ï¸ Aucun Ã©vÃ©nement de produit non trouvÃ© pour le magasin {shop_code}")
            return True
        
        # Exporter vers CSV
        logger.info("=" * 60)
        logger.info(f"ğŸ’¾ EXPORT CSV - MAGASIN {shop_code}")
        logger.info("=" * 60)
        csv_file = self.export_to_csv(events, shop_code, shop_name)
        if csv_file:
            logger.info("=" * 60)
            logger.info(f"âœ… MAGASIN {shop_code} TRAITÃ‰ AVEC SUCCÃˆS")
            logger.info("=" * 60)
            logger.info(f"ğŸ“ Fichier sur le rÃ©seau: {csv_file}")
            logger.info(f"ğŸ“Š Lignes exportÃ©es: {len(events):,}")
            logger.info("=" * 60)
            return True
        else:
            logger.error(f"âŒ Erreur lors de l'export pour le magasin {shop_code}")
            return False

    def extract_all(self):
        """Extrait les Ã©vÃ©nements pour tous les magasins configurÃ©s"""
        logger.info("=" * 60)
        logger.info("DÃ‰BUT DE L'EXTRACTION API PROSUMA - PRODUITS NON TROUVÃ‰S")
        logger.info("=" * 60)
        
        # CrÃ©er le dossier rÃ©seau au dÃ©but
        network_path = self.get_network_path_for_shop("PRODUIT_NON_TROUVE")
        if network_path:
            logger.info(f"âœ… Dossier rÃ©seau crÃ©Ã©: {network_path}")
        else:
            logger.warning("âš ï¸ Impossible de crÃ©er le dossier rÃ©seau")
        
        successful_shops = 0
        total_shops = len(self.shop_codes)
        
        for shop_code in self.shop_codes:
            try:
                if self.extract_shop(shop_code):
                    successful_shops += 1
            except Exception as e:
                logger.error(f"âŒ Erreur lors de l'extraction du magasin {shop_code}: {e}")
        
        # RÃ©sumÃ©
        logger.info("=" * 60)
        logger.info("RÃ‰SUMÃ‰ DE L'EXTRACTION")
        logger.info("=" * 60)
        logger.info(f"Magasins traitÃ©s avec succÃ¨s: {successful_shops}/{total_shops}")
        
        if successful_shops == total_shops:
            logger.info("âœ… Extraction complÃ¨tement rÃ©ussie")
        elif successful_shops > 0:
            logger.warning(f"âš ï¸ Extraction partiellement rÃ©ussie ({successful_shops}/{total_shops})")
        else:
            logger.error("âŒ Aucune extraction rÃ©ussie")

def main():
    """Fonction principale"""
    try:
        extractor = ProsumaAPIProduitNonTrouveExtractor()
        extractor.extract_all()
    except Exception as e:
        print(f"âŒ Erreur fatale: {e}")

if __name__ == "__main__":
    main()