#!/usr/bin/env python3
"""
Extracteur API Prosuma RPOS - Commandes R√©assort
R√©cup√®re les commandes r√©assort via l'API Prosuma avec pagination automatique
"""

import requests
import os
import csv
import json
import logging
import shutil
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv
import urllib3
import sys

# Ajouter le r√©pertoire parent au path pour importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import load_shop_config, build_network_path, create_network_folder, SafeStreamHandler

# D√©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class ProsumaAPICommandeReassortExtractor:
    def __init__(self):
        """Initialise l'extracteur avec la configuration"""
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        load_dotenv(os.path.join(project_root, 'config.env'))
        
        self.username = os.getenv('PROSUMA_USER')
        self.password = os.getenv('PROSUMA_PASSWORD')
        self.status_filter = os.getenv('STATUT_COMMANDE', '')
        
        if not self.username or not self.password:
            raise ValueError("PROSUMA_USER et PROSUMA_PASSWORD doivent √™tre configur√©s dans config.env")
        
        # Configuration du dossier de t√©l√©chargement
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.network_folder_base = os.getenv('DOWNLOAD_FOLDER_BASE', '\\10.0.70.169\\share\\FOFANA')
        
        # Configuration des magasins
        self.shop_config = load_shop_config(os.path.dirname(self.base_dir))
        self.shop_codes = list(self.shop_config.keys())
        
        # Configuration des dates (hier -> aujourd'hui par d√©faut)
        self.setup_dates()
        
        # Configuration du logging sera faite dans setup_logging()
        self.setup_logging()
        
        # Configuration de la session
        self.session = requests.Session()
        self.session.auth = (self.username, self.password)
        self.session.verify = False
        
        print(f"Extracteur API Commandes R√©assort initialis√© pour {self.username}")
        print(f"Magasins configur√©s: {self.shop_codes}")
        print(f"P√©riode: {self.start_date.strftime('%Y-%m-%d')} √† {self.end_date.strftime('%Y-%m-%d')}")
        if self.status_filter:
            print(f"Filtre de statut: {self.status_filter}")

    def setup_logging(self):
        """Configure le syst√®me de logging"""
        # Essayer d'abord le dossier r√©seau, puis fallback local
        log_file = None
        log_network_path = self.get_log_network_path()
        
        if log_network_path:
            try:
                # V√©rifier que le dossier existe et est accessible
                if os.path.exists(log_network_path) and os.access(log_network_path, os.W_OK):
            log_file = os.path.join(log_network_path, f'api_commande_reassort_{datetime.now().strftime("%Y%m%d")}.log')
                    # Tester l'√©criture
                    try:
                        test_file = os.path.join(log_network_path, '.test_write')
                        with open(test_file, 'w') as f:
                            f.write('test')
                        os.remove(test_file)
                    except (PermissionError, OSError):
                        # Pas d'acc√®s en √©criture, utiliser le fallback local
                        log_file = None
        else:
                    log_file = None
            except Exception as e:
                # Erreur d'acc√®s au r√©seau, utiliser le fallback local
                log_file = None
        
        # Fallback local si le r√©seau n'est pas accessible
        if not log_file:
            # Cr√©er un dossier LOG local s'il n'existe pas
            local_log_dir = os.path.join(self.base_dir, 'LOG')
            try:
                if not os.path.exists(local_log_dir):
                    os.makedirs(local_log_dir, exist_ok=True)
                log_file = os.path.join(local_log_dir, f'api_commande_reassort_{datetime.now().strftime("%Y%m%d")}.log')
            except Exception as e:
                # Dernier recours : utiliser le dossier de base
            log_file = os.path.join(self.base_dir, f'api_commande_reassort_{datetime.now().strftime("%Y%m%d")}.log')
        
        # Configuration du logging avec gestion d'erreur
        try:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                SafeStreamHandler()
            ]
        )
            
            # D√©finir les permissions pour permettre √† tous les utilisateurs d'√©crire
            from utils import set_log_file_permissions
            set_log_file_permissions(log_file)
            
        except (PermissionError, OSError) as e:
            # Si l'√©criture √©choue, utiliser seulement le stream handler
            print(f"‚ö†Ô∏è Impossible d'√©crire dans le fichier de log {log_file}: {e}")
            print("‚ö†Ô∏è Les logs seront affich√©s uniquement dans la console")
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s',
                handlers=[SafeStreamHandler()]
            )
        
        global logger
        logger = logging.getLogger(__name__)
        logger.info(f"üìù Fichier de log: {log_file}")

    def setup_dates(self):
        """Configure les dates d'extraction"""
        # V√©rifier si des dates personnalis√©es sont fournies via les variables d'environnement
        start_date_str = os.getenv('DATE_START')
        end_date_str = os.getenv('DATE_END')
        
        if start_date_str and end_date_str:
            try:
                # Parser les dates
                start_date_only = datetime.strptime(start_date_str, '%Y-%m-%d')
                end_date_only = datetime.strptime(end_date_str, '%Y-%m-%d')
                
                # Ajouter les heures appropri√©es
                self.start_date = start_date_only.replace(hour=0, minute=0, second=0, microsecond=0)
                self.end_date = end_date_only.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                print(f"Dates personnalis√©es: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
            except ValueError:
                print("Format de date invalide, utilisation des dates par d√©faut")
                self.setup_default_dates()
        else:
            # Utiliser les dates par d√©faut (hier -> aujourd'hui)
            self.setup_default_dates()
    
    def setup_default_dates(self):
        """Configure les dates par d√©faut (hier -> aujourd'hui)"""
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        
        # Ajouter les heures appropri√©es
        self.start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
        self.end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        print(f"Dates par d√©faut: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")

    def get_shop_folder_name(self, shop_code):
        """Retourne le nom du dossier pour un magasin sp√©cifique bas√© sur le mapping"""
        shop_info = self.shop_config.get(shop_code)
        if not shop_info:
            return None
        
        shop_name = shop_info.get('name', '')
        
        # Mapping des noms de magasins vers les noms de dossiers
        folder_mapping = {
            'HYPER CASINO PRIMA': 'PRIMA',
            'CASINO MANDARINE RIVIERA 4': 'SOL BENI',  # Le dossier reste SOL BENI mais le magasin est CASINO MANDARINE RIVIERA 4
            'MANDARINE KOUMASSI': 'CKM',  # Le dossier reste CKM mais le magasin est MANDARINE KOUMASSI
            'CASH IVOIRE U 7 DECEMBRE': 'CUV7DEC',
            'MANDARINE GOLF': 'MANDARINE GOLF',
            'CASINO ALLABRA': 'CASINO ALLABRA',
            'SUPER U VALLON': 'SUPER U VALLON',
            'CASH IVOIRE U M\'BADON': 'MBADON',
            # Ajouter d'autres mappings si n√©cessaire
        }
        
        # Chercher le mapping exact
        if shop_name in folder_mapping:
            return folder_mapping[shop_name]
        
        # Si pas de mapping exact, utiliser le nom du magasin tel quel
        # (pour les autres magasins qui n'ont pas encore de dossier)
        return shop_name

    def get_network_path_for_shop(self, shop_code):
        """Retourne le chemin r√©seau pour un magasin sp√©cifique dans ASTEN"""
        try:
            # Chemin de base: \\10.0.70.169\share\FOFANA\Etats Natacha\Commande\PRESENTATION_COMMANDE\ASTEN
            base = self.network_folder_base.replace('/', '\\')
            if base.endswith('\\'):
                base = base[:-1]
            
            asten_path = f"{base}\\Etats Natacha\\Commande\\PRESENTATION_COMMANDE\\ASTEN"
            
            # Obtenir le nom du dossier pour ce magasin
            folder_name = self.get_shop_folder_name(shop_code)
            if not folder_name:
                logger.warning(f"‚ö†Ô∏è Impossible de d√©terminer le nom du dossier pour le magasin {shop_code}")
                return None
            
            # Chemin complet: ASTEN\{NOM_DOSSIER}
            network_path = os.path.join(asten_path, folder_name)
            logger.debug(f"Chemin r√©seau calcul√© pour {shop_code}: {network_path}")
            
            # Cr√©er le dossier s'il n'existe pas
        if create_network_folder(network_path):
                # V√©rifier que le dossier existe vraiment
                if os.path.exists(network_path):
                    logger.debug(f"‚úÖ Dossier r√©seau v√©rifi√©: {network_path}")
            return network_path
                else:
                    logger.warning(f"‚ö†Ô∏è Le dossier r√©seau n'existe pas apr√®s cr√©ation: {network_path}")
                    return None
            else:
                logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier r√©seau: {network_path}")
                return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la cr√©ation du chemin r√©seau pour {shop_code}: {e}")
        return None
        
    def get_log_network_path(self):
        """Retourne le chemin r√©seau pour les logs"""
        if not self.network_folder_base:
            return None
        # Chemin: \\10.0.70.169\share\FOFANA\Etats Natacha\SCRIPT\LOG
        base = self.network_folder_base.replace('/', '\\')
        if base.endswith('\\'):
            base = base[:-1]
        log_path = f"{base}\\Etats Natacha\\SCRIPT\\LOG"
        if create_network_folder(log_path):
            return log_path
        return None

    def test_api_connection(self, base_url):
        """Teste la connexion √† l'API"""
        try:
            test_url = f"{base_url}/api/user/"
            response = self.session.get(test_url, timeout=10)
            if response.status_code == 200:
                logger.info(f"‚úÖ Connexion API r√©ussie: {base_url}")
                return True
            else:
                logger.error(f"‚ùå Erreur de connexion API {base_url}: {response.status_code} {response.text}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erreur de connexion API {base_url}: {e}")
            return False

    def get_shop_info(self, base_url, shop_code):
        """R√©cup√®re les informations d'un magasin"""
        try:
            # Essayer d'abord avec l'endpoint direct
            url = f"{base_url}/api/shop/{shop_code}/"
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                shop_data = response.json()
                if isinstance(shop_data, dict) and shop_data.get('reference') == shop_code:
                    logger.info(f"‚úÖ Magasin {shop_code} trouv√©: {shop_data.get('name', 'Nom inconnu')}")
                    return shop_data
            
            # Si pas trouv√©, chercher dans la liste pagin√©e
            url = f"{base_url}/api/shop/"
            page = 1
            while True:
                params = {'page': page, 'page_size': 100}
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    shops = data.get('results', [])
                    
                    for shop in shops:
                        if shop.get('reference') == shop_code:
                            logger.info(f"‚úÖ Magasin {shop_code} trouv√©: {shop.get('name', 'Nom inconnu')}")
                            return shop
                    
                    if not data.get('next'):
                        break
                    page += 1
                else:
                    break
            
            logger.warning(f"‚ö†Ô∏è Magasin {shop_code} non trouv√© dans la liste")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des informations du magasin: {e}")
            return None

    def get_supplier_info(self, base_url, supplier_id):
        """R√©cup√®re les informations compl√®tes d'un fournisseur via l'API /api/supplier/{id}/"""
        if not supplier_id:
            return None
        
        try:
            # Essayer d'abord avec l'endpoint direct
            url = f"{base_url}/api/supplier/{supplier_id}/"
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                supplier_data = response.json()
                if isinstance(supplier_data, dict):
                    return supplier_data
            
            # Si pas trouv√©, chercher dans la liste pagin√©e
            url = f"{base_url}/api/supplier/"
            page = 1
            while True:
                params = {'page': page, 'page_size': 100}
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    suppliers = data.get('results', [])
                    
                    for supplier in suppliers:
                        if supplier.get('id') == supplier_id:
                            return supplier
                    
                    if not data.get('next'):
                        break
                    page += 1
                else:
                    break
            
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration du fournisseur {supplier_id}: {e}")
            return None

    def enrich_orders_with_supplier_info(self, base_url, orders):
        """Enrichit les commandes avec les informations compl√®tes du fournisseur (is_central)"""
        if not orders:
            return orders
        
        logger.info(f"üîç Enrichissement des commandes avec les informations des fournisseurs...")
        
        # Collecter tous les IDs de fournisseurs uniques
        supplier_ids = set()
        for order in orders:
            supplier = order.get('supplier', {})
            if isinstance(supplier, dict):
                supplier_id = supplier.get('id')
                if supplier_id:
                    supplier_ids.add(supplier_id)
            elif isinstance(supplier, str):
                # Si supplier est une URL, extraire l'ID
                if supplier.endswith('/'):
                    supplier = supplier[:-1]
                supplier_id = supplier.split('/')[-1]
                if supplier_id:
                    supplier_ids.add(supplier_id)
        
        logger.info(f"   üìä {len(supplier_ids)} fournisseur(s) unique(s) √† r√©cup√©rer")
        
        # Cr√©er un cache pour les informations des fournisseurs
        supplier_cache = {}
        for supplier_id in supplier_ids:
            supplier_info = self.get_supplier_info(base_url, supplier_id)
            if supplier_info:
                supplier_cache[supplier_id] = supplier_info
        
        logger.info(f"   ‚úÖ {len(supplier_cache)} fournisseur(s) r√©cup√©r√©(s)")
        
        # Enrichir les commandes avec les informations du fournisseur
        enriched_count = 0
        for order in orders:
            supplier = order.get('supplier', {})
            supplier_id = None
            
            if isinstance(supplier, dict):
                supplier_id = supplier.get('id')
            elif isinstance(supplier, str):
                # Si supplier est une URL, extraire l'ID
                if supplier.endswith('/'):
                    supplier = supplier[:-1]
                supplier_id = supplier.split('/')[-1]
            
            if supplier_id and supplier_id in supplier_cache:
                supplier_info = supplier_cache[supplier_id]
                # Ajouter is_central au supplier de la commande
                if isinstance(order.get('supplier'), dict):
                    order['supplier']['is_central'] = supplier_info.get('is_central', False)
                    enriched_count += 1
        
        logger.info(f"   ‚úÖ {enriched_count} commande(s) enrichie(s) avec is_central")
        return orders

    def count_total_records(self, base_url, shop_id, page_size=1000):
        """Compte le nombre total de commandes r√©assort disponibles"""
        try:
            url = f"{base_url}/api/supplier_order/"
            params = {
                'shop': shop_id,
                'page_size': page_size,
                'page': 1,
                'is_external': 'true',
                'is_direct': 'false',  # Exclure les commandes directes pour ne garder que les r√©assort
                'date_0': self.start_date.strftime('%Y-%m-%dT00:00:00'),
                'date_1': self.end_date.strftime('%Y-%m-%dT23:59:59')
            }
            if self.status_filter and self.status_filter.lower() == 'en attente de livraison':
                params['is_awaiting_delivery'] = 'true'
            
            response = self.session.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                total_count = data.get('count', 0)
                return total_count
            else:
                logger.error(f"‚ùå Erreur lors du comptage: {response.status_code}")
                return 0
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du comptage: {e}")
            return 0

    def get_orders(self, base_url, shop_id, page_size=1000):
        """R√©cup√®re les commandes r√©assort avec pagination compl√®te"""
        # D'abord, compter le nombre total de commandes
        logger.info("üîç Comptage du nombre total de commandes r√©assort...")
        total_records = self.count_total_records(base_url, shop_id, page_size)
        
        if total_records == 0:
            logger.warning("‚ö†Ô∏è Aucune commande r√©assort trouv√©e")
            return []
        
        # Afficher le cadre avec le nombre total
        logger.info("=" * 60)
        logger.info(f"üìä INFORMATIONS D'EXTRACTION - MAGASIN {shop_id}")
        logger.info("=" * 60)
        logger.info(f"üìä Total commandes r√©assort disponibles: {total_records:,}")
        logger.info(f"üìÖ P√©riode: {self.start_date.strftime('%Y-%m-%d %H:%M:%S')} √† {self.end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"üè™ Magasin: {shop_id}")
        logger.info("=" * 60)
        
        try:
            url = f"{base_url}/api/supplier_order/"
            params = {
                'shop': shop_id,
                'page_size': page_size,
                'is_external': 'true',
                'is_direct': 'false',  # Exclure les commandes directes pour ne garder que les r√©assort
                'date_0': self.start_date.strftime('%Y-%m-%dT00:00:00'),
                'date_1': self.end_date.strftime('%Y-%m-%dT23:59:59')
            }
            if self.status_filter and self.status_filter.lower() == 'en attente de livraison':
                params['is_awaiting_delivery'] = 'true'
                logger.info(f"Filtre API: is_awaiting_delivery=true")
            
            logger.info(f"üîç Filtres API appliqu√©s:")
            logger.info(f"   - is_external: true (commandes externes)")
            logger.info(f"   - is_direct: false (exclure les commandes directes)")
            if self.status_filter:
                logger.info(f"   - status: {self.status_filter}")
            
            all_orders = []
            page = 1
            total_pages = (total_records + page_size - 1) // page_size
            
            while page <= total_pages:
                # Afficher la progression
                progress_percent = (page - 1) * 100 // total_pages if total_pages > 0 else 0
                logger.info(f"üìÑ R√©cup√©ration page {page}/{total_pages} ({progress_percent}%) - {len(all_orders):,}/{total_records:,} commandes...")
                
                params['page'] = page
                
                response = self.session.get(url, params=params, timeout=60)
                response.raise_for_status()
                data = response.json()
                
                orders_on_page = data.get('results', [])
                all_orders.extend(orders_on_page)
                
                logger.info(f"  ‚úÖ Page {page}: {len(orders_on_page)} commandes r√©assort r√©cup√©r√©es (total: {len(all_orders):,}/{total_records:,})")
                
                # V√©rifier s'il y a une page suivante
                if not data.get('next'):
                    logger.info(f"  ‚úÖ Derni√®re page atteinte (page {page})")
                    break
                
                page += 1
            
            # Enrichir les commandes avec les informations compl√®tes des fournisseurs
            all_orders = self.enrich_orders_with_supplier_info(base_url, all_orders)
            
            # Filtrage de s√©curit√© : utiliser supplier.is_central pour identifier les r√©assort
            # Selon la documentation API: is_central=True = fournisseur centrale = r√©assort
            original_count = len(all_orders)
            filtered_orders = []
            direct_orders_excluded = 0
            
            # Analyser la premi√®re commande pour voir la structure
            if all_orders:
                first_order = all_orders[0]
                supplier = first_order.get('supplier', {})
                has_supplier = isinstance(supplier, dict) and supplier
                has_is_central = has_supplier and 'is_central' in supplier
                
                logger.info(f"üîç Analyse des champs API:")
                logger.info(f"   - supplier pr√©sent: {'‚úÖ OUI' if has_supplier else '‚ùå NON'}")
                if has_supplier:
                    logger.info(f"   - supplier.is_central pr√©sent: {'‚úÖ OUI' if has_is_central else '‚ùå NON'}")
                    if has_is_central:
                        logger.info(f"   - Valeur supplier.is_central: {supplier.get('is_central')}")
                
                if has_is_central:
                    # Le champ is_central existe, on peut filtrer strictement
                    for order in all_orders:
                        supplier = order.get('supplier', {})
                        if isinstance(supplier, dict):
                            is_central = supplier.get('is_central', False)
                            
                            # Les r√©assort sont les commandes avec supplier.is_central=True
                            if is_central:
                                filtered_orders.append(order)
                            else:
                                direct_orders_excluded += 1
                                logger.debug(f"‚ùå Commande directe exclue: {order.get('reference', order.get('id', 'N/A'))} (supplier.is_central=False)")
                        else:
                            # Pas de fournisseur, exclure par s√©curit√©
                            direct_orders_excluded += 1
                            logger.debug(f"‚ùå Commande sans fournisseur exclue: {order.get('reference', order.get('id', 'N/A'))}")
                else:
                    # Le champ is_central n'existe toujours pas apr√®s enrichissement
                    logger.warning(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ATTENTION: Le champ supplier.is_central n'existe toujours pas apr√®s enrichissement ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
                    logger.warning(f"   On fait confiance au filtre API (is_external=true, is_direct=false)")
                    logger.warning(f"   Toutes les {original_count} commandes sont accept√©es comme r√©assort")
                    filtered_orders = all_orders.copy()
            
            all_orders = filtered_orders
            filtered_count = len(all_orders)
            
            if direct_orders_excluded > 0:
                logger.warning(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è FILTRE DE S√âCURIT√â: {direct_orders_excluded} commande(s) directe(s) exclue(s) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
                logger.warning(f"   Le filtre API n'a pas fonctionn√© correctement.")
                logger.warning(f"   Filtrage manuel strict: {original_count} -> {filtered_count} commandes r√©assort")
                logger.warning(f"   Crit√®re: supplier.is_central=True (fournisseur centrale)")
            elif original_count > 0:
                logger.info(f"‚úÖ‚úÖ‚úÖ Filtre de s√©curit√©: {filtered_count} commandes r√©assort valid√©es (supplier.is_central=True)")
            
            # Filtrage post-r√©cup√©ration si n√©cessaire (seulement pour les filtres autres que "en attente de livraison")
            # Le filtre "en attente de livraison" est d√©j√† appliqu√© via le param√®tre API is_awaiting_delivery
            if self.status_filter and self.status_filter.lower() != 'en attente de livraison':
                logger.info(f"Filtrage post-r√©cup√©ration pour le statut: '{self.status_filter}'")
                original_count = len(all_orders)
                all_orders = [order for order in all_orders 
                              if (order.get('status_display') or order.get('status', '')).lower() == self.status_filter.lower()]
                filtered_count = len(all_orders)
                logger.info(f"Filtrage: {original_count} -> {filtered_count} commandes")
            
            # V√©rifier que le filtre "en attente de livraison" fonctionne correctement
            if self.status_filter and self.status_filter.lower() == 'en attente de livraison':
                # V√©rifier que toutes les commandes sont bien en attente de livraison
                # Le filtre API devrait d√©j√† avoir filtr√©, mais on v√©rifie quand m√™me
                original_count = len(all_orders)
                all_orders = [order for order in all_orders 
                              if order.get('is_awaiting_delivery', False) or 
                                 (order.get('status_display', '').lower() in ['en attente de livraison', 'awaiting delivery'])]
                filtered_count = len(all_orders)
                if original_count != filtered_count:
                    logger.warning(f"‚ö†Ô∏è Le filtre API n'a pas fonctionn√© correctement. Filtrage manuel: {original_count} -> {filtered_count} commandes")
                else:
                    logger.info(f"‚úÖ Filtre 'en attente de livraison' appliqu√©: {filtered_count} commandes")

            # Afficher le r√©sum√© final
            logger.info("=" * 60)
            if len(all_orders) > 0:
                logger.info(f"‚úÖ R√âSUM√â EXTRACTION - MAGASIN {shop_id} - SUCC√àS")
            else:
                logger.warning(f"‚ö†Ô∏è R√âSUM√â EXTRACTION - MAGASIN {shop_id} - AUCUNE DONN√âE")
            logger.info("=" * 60)
            logger.info(f"üìä Commandes trouv√©es: {total_records:,}")
            logger.info(f"üì• Commandes extraites: {len(all_orders):,}")
            if total_records > 0:
                success_rate = (len(all_orders)/total_records*100)
                if success_rate == 100:
                    logger.info(f"üìà Taux de r√©ussite: {success_rate:.1f}% ‚úÖ")
                elif success_rate >= 50:
                    logger.info(f"üìà Taux de r√©ussite: {success_rate:.1f}% ‚ö†Ô∏è")
                else:
                    logger.warning(f"üìà Taux de r√©ussite: {success_rate:.1f}% ‚ùå")
            else:
                logger.warning(f"üìà Taux de r√©ussite: 0% ‚ùå")
            logger.info("=" * 60)
            
            if len(all_orders) > 0:
            logger.info(f"‚úÖ {len(all_orders)} commandes r√©assort r√©cup√©r√©es au total")
            else:
                logger.warning(f"‚ö†Ô∏è Aucune commande r√©assort r√©cup√©r√©e")
            return all_orders
            
        except Exception as e:
            logger.error(f"‚ùå ERREUR lors de la r√©cup√©ration des commandes r√©assort: {e}")
            logger.error(f"‚ùå EXTRACTION √âCHOU√âE pour le magasin {shop_id}")
            return []

    def export_to_csv(self, orders, shop_code, shop_name):
        """Exporte les commandes r√©assort vers un fichier CSV"""
        if not orders:
            logger.warning(f"‚ö†Ô∏è Aucune commande r√©assort √† exporter pour le magasin {shop_code}")
            return None
        
        # Cr√©er le dossier local EXPORT
        local_export_dir = os.path.join(self.base_dir, 'EXPORT')
        try:
            os.makedirs(local_export_dir, exist_ok=True)
            logger.info(f"‚úÖ Dossier local EXPORT cr√©√©/v√©rifi√©: {local_export_dir}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier local EXPORT: {e}")
            local_export_dir = self.base_dir  # Fallback vers le dossier de base
        
        # Cr√©er le dossier r√©seau
        network_path = self.get_network_path_for_shop(shop_code)
        if not network_path:
            logger.error(f"‚ùå Impossible de cr√©er le dossier r√©seau pour le magasin {shop_code}")
            logger.error(f"   Le fichier sera uniquement sauvegard√© localement dans: {local_export_dir}")
        else:
            logger.info(f"‚úÖ Dossier r√©seau trouv√©/cr√©√©: {network_path}")
        
        # Cr√©er un fichier temporaire local dans EXPORT
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'export_commande_reassort_{shop_code}_{timestamp}.csv'
        local_filepath = os.path.join(local_export_dir, filename)
        
        # En-t√™tes CSV exacts demand√©s par l'utilisateur + colonnes de v√©rification
        fieldnames = [
            "id",
            "Magasin", 
            "Code communication",
            "R√©f√©rence commande",
            "R√©f√©rence commande externe",
            "R√©f√©rence pr√© commande",
            "Configuration commande externe",
            "Date commande",
            "Date livraison",
            "Date validation",
            "Date de d√©but de validation",
            "Date de fin de validation",
            "Statut",
            "Cr√©√©e par",
            "Valid√©e par",
            "Fournisseur",
            "Nom",
            "Pr√©nom",
            "Titre",
            "Adresse 1",
            "Adresse 2",
            "Adresse 3",
            "Code postal",
            "Ville",
            "Pays",
            "T√©l√©phone 1",
            "T√©l√©phone 2",
            "Fax",
            "Email",
            "Entreprise",
            "Num√©ro T.V.A. intra.",
            "A.P.E.",
            "SIRET",
            "SIREN",
            "Historique",
            "Type commande",  # Nouvelle colonne pour identifier le type
            "supplier.is_central",  # Colonne de v√©rification (fournisseur centrale)
            "Fournisseur centrale"  # Colonne de v√©rification (r√©assort)
        ]
        
        try:
            # Cr√©er le fichier CSV local
            with open(local_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')
                writer.writeheader()
                
                for order in orders:
                    # D√©terminer le type de commande bas√© sur supplier.is_central
                    supplier = order.get('supplier', {})
                    is_central = False
                    if isinstance(supplier, dict):
                        is_central = supplier.get('is_central', False)
                    
                    if is_central:
                        type_commande = "R√âASSORT"
                    else:
                        type_commande = "DIRECTE"
                    
                    # Pr√©parer les donn√©es pour l'export avec mapping complet
                    row = {
                        "id": order.get('id', ''),
                        "Magasin": shop_code,  # Utiliser le code du magasin
                        "Code communication": order.get('code_com', ''),
                        "R√©f√©rence commande": order.get('reference', ''),
                        "R√©f√©rence commande externe": order.get('external_reference', ''),
                        "R√©f√©rence pr√© commande": order.get('pre_order_code_com', ''),
                        "Configuration commande externe": order.get('external_order_config', ''),
                        "Date commande": self.format_date(order.get('date', '')),
                        "Date livraison": self.format_date(order.get('delivery_date', '')),
                        "Date validation": self.format_date(order.get('validation_date', '')),
                        "Date de d√©but de validation": self.format_date(order.get('start_date', '')),
                        "Date de fin de validation": self.format_date(order.get('end_date', '')),
                        "Statut": order.get('status_display', order.get('status', '')),
                        "Cr√©√©e par": order.get('created_by', ''),
                        "Valid√©e par": order.get('validated_by', ''),
                        "Fournisseur": order.get('supplier', {}).get('name', '') if isinstance(order.get('supplier'), dict) else '',
                        "Nom": order.get('last_name', ''),
                        "Pr√©nom": order.get('first_name', ''),
                        "Titre": order.get('title', {}).get('display_name', '') if isinstance(order.get('title'), dict) else '',
                        "Adresse 1": order.get('address_1', ''),
                        "Adresse 2": order.get('address_2', ''),
                        "Adresse 3": order.get('address_3', ''),
                        "Code postal": order.get('postal_code', ''),
                        "Ville": order.get('city', ''),
                        "Pays": order.get('country', {}).get('display_name', '') if isinstance(order.get('country'), dict) else '',
                        "T√©l√©phone 1": order.get('phone_1', ''),
                        "T√©l√©phone 2": order.get('phone_2', ''),
                        "Fax": order.get('fax', ''),
                        "Email": order.get('email', ''),
                        "Entreprise": order.get('company_name', ''),
                        "Num√©ro T.V.A. intra.": order.get('vat_number', ''),
                        "A.P.E.": order.get('ape_code', ''),
                        "SIRET": order.get('siret_number', ''),
                        "SIREN": order.get('siren_number', ''),
                        "Historique": order.get('history', ''),
                        "Type commande": type_commande,
                        "supplier.is_central": "OUI" if is_central else "NON",
                        "Fournisseur centrale": "OUI" if is_central else "NON"
                    }
                    writer.writerow(row)
            
            logger.info(f"‚úÖ Fichier CSV cr√©√© localement: {local_filepath}")
            logger.info(f"   üìä {len(orders)} commandes r√©assort export√©es")
            logger.info(f"   üìã {len(fieldnames)} colonnes par commande")
            
            # Copier vers le r√©seau si le chemin r√©seau est disponible
            if network_path:
                # Utiliser os.path.join mais corriger pour les chemins UNC Windows
                if network_path.startswith('\\\\'):
                    # Chemin UNC, utiliser directement la concat√©nation avec backslash
                    network_filepath = f"{network_path}\\{filename}" if not network_path.endswith('\\') else f"{network_path}{filename}"
                else:
            network_filepath = os.path.join(network_path, filename)
                try:
                    # V√©rifier que le dossier r√©seau existe
                    if not os.path.exists(network_path):
                        logger.warning(f"‚ö†Ô∏è Le dossier r√©seau n'existe pas: {network_path}")
                        logger.info(f"   Tentative de cr√©ation...")
                        if create_network_folder(network_path):
                            logger.info(f"   ‚úÖ Dossier cr√©√© avec succ√®s")
                        else:
                            logger.error(f"   ‚ùå Impossible de cr√©er le dossier")
                            logger.info(f"üìÅ Fichier conserv√© uniquement localement: {local_filepath}")
                            return local_filepath
                    
                    # Copier le fichier
                    logger.info(f"üìã Tentative de copie vers: {network_filepath}")
                    try:
            shutil.copy2(local_filepath, network_filepath)
                        logger.info(f"‚úÖ Commande copy2 ex√©cut√©e sans erreur")
                    except Exception as copy_ex:
                        logger.error(f"‚ùå‚ùå‚ùå ERREUR LORS DE LA COPIE ‚ùå‚ùå‚ùå")
                        logger.error(f"   Exception: {copy_ex}")
                        logger.error(f"   Type: {type(copy_ex).__name__}")
                        raise
                    
                    # Attendre un peu pour que Windows synchronise
                    time.sleep(0.5)
                    
                    # V√©rifier que la copie a r√©ussi avec plusieurs m√©thodes
                    file_exists = os.path.exists(network_filepath)
                    file_readable = False
                    file_size_network = 0
                    file_size_local = os.path.getsize(local_filepath)
                    
                    if file_exists:
                        try:
                            file_size_network = os.path.getsize(network_filepath)
                            # Essayer d'ouvrir le fichier en lecture pour v√©rifier qu'il est accessible
                            with open(network_filepath, 'r', encoding='utf-8-sig') as f:
                                f.read(1)  # Lire au moins 1 caract√®re
                            file_readable = True
                        except Exception as read_ex:
                            logger.warning(f"‚ö†Ô∏è Le fichier existe mais n'est pas lisible: {read_ex}")
                    
                    if file_exists and file_readable and file_size_network == file_size_local:
                        logger.info(f"‚úÖ‚úÖ‚úÖ FICHIER COPI√â SUR LE R√âSEAU AVEC SUCC√àS ‚úÖ‚úÖ‚úÖ")
                        logger.info(f"   üìÅ Chemin r√©seau: {network_filepath}")
                        logger.info(f"   üìä Taille locale: {file_size_local:,} octets")
                        logger.info(f"   üìä Taille r√©seau: {file_size_network:,} octets")
                        logger.info(f"   ‚úÖ Fichier v√©rifi√© et accessible")
                        logger.info(f"üìÅ Fichier local conserv√© dans EXPORT: {local_filepath}")
                        # IMPORTANT: Retourner le chemin r√©seau si la copie a r√©ussi
            return network_filepath
                    elif file_exists:
                        logger.warning(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è FICHIER COPI√â MAIS PROBL√àME DE V√âRIFICATION ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
                        logger.warning(f"   üìÅ Chemin r√©seau: {network_filepath}")
                        logger.warning(f"   üìä Taille locale: {file_size_local:,} octets")
                        logger.warning(f"   üìä Taille r√©seau: {file_size_network:,} octets")
                        logger.warning(f"   ‚ö†Ô∏è Fichier existe mais peut ne pas √™tre accessible")
                        logger.info(f"üìÅ Fichier local conserv√©: {local_filepath}")
                        return local_filepath
                    else:
                        logger.error(f"‚ùå‚ùå‚ùå LE FICHIER N'EXISTE PAS APR√àS LA COPIE ‚ùå‚ùå‚ùå")
                        logger.error(f"   Chemin attendu: {network_filepath}")
                        logger.error(f"   V√©rification os.path.exists(): {file_exists}")
                        logger.error(f"   Taille locale: {file_size_local:,} octets")
                        logger.info(f"üìÅ Fichier conserv√© uniquement localement: {local_filepath}")
                        return local_filepath
                        
                except PermissionError as e:
                    logger.error(f"‚ùå Erreur de permission lors de la copie sur le r√©seau: {e}")
                    logger.info(f"üìÅ Fichier conserv√© uniquement localement: {local_filepath}")
                    return local_filepath
                except Exception as e:
                    logger.error(f"‚ùå Erreur lors de la copie sur le r√©seau: {e}")
                    logger.info(f"üìÅ Fichier conserv√© uniquement localement: {local_filepath}")
                    return local_filepath
            else:
                logger.warning(f"‚ö†Ô∏è Pas de chemin r√©seau disponible, fichier conserv√© uniquement localement")
                return local_filepath
            
            # Si on arrive ici, la copie r√©seau a √©chou√© ou n'a pas √©t√© tent√©e
            # Retourner le chemin local
            logger.info(f"üìÅ Fichier local conserv√© dans EXPORT: {local_filepath}")
            return local_filepath
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'export CSV: {e}")
            return None

    def format_date(self, date_value):
        """Formate une date pour l'affichage"""
        if not date_value:
            return ''
        
        try:
            if 'T' in str(date_value):
                # Format ISO avec heure
                dt = datetime.fromisoformat(str(date_value).replace('Z', '+00:00'))
                return dt.strftime('%d/%m/%Y %H:%M:%S')
            elif len(str(date_value)) == 10:
                # Format YYYY-MM-DD
                dt = datetime.strptime(str(date_value), '%Y-%m-%d')
                return dt.strftime('%d/%m/%Y')
            else:
                return str(date_value)
        except:
            return str(date_value)

    def extract_shop(self, shop_code):
        """Extrait les commandes r√©assort pour un magasin sp√©cifique"""
        shop_info = self.shop_config.get(shop_code)
        if not shop_info:
            logger.error(f"‚ùå Configuration manquante pour le magasin {shop_code}")
            return False
        
        base_url = shop_info['url']
        shop_name = shop_info['name']
        
        logger.info(f"==================================================")
        logger.info(f"üöÄ EXTRACTION COMMANDES R√âASSORT MAGASIN {shop_code}")
        logger.info(f"==================================================")
        logger.info(f"üåê URL serveur: {base_url}")
        logger.info(f"üè™ Nom magasin: {shop_name}")
        
        # Test de connexion
        if not self.test_api_connection(base_url):
            logger.error(f"‚ùå‚ùå‚ùå IMPOSSIBLE DE SE CONNECTER AU SERVEUR ‚ùå‚ùå‚ùå")
            logger.error(f"   Serveur: {base_url}")
            logger.error(f"   Magasin {shop_code}: √âCHEC")
            return False
        
        # R√©cup√©rer les informations du magasin
        logger.info(f"üîç R√©cup√©ration des informations du magasin {shop_code}...")
        shop_data = self.get_shop_info(base_url, shop_code)
        if not shop_data:
            logger.error(f"‚ùå‚ùå‚ùå IMPOSSIBLE DE R√âCUP√âRER LES INFORMATIONS DU MAGASIN ‚ùå‚ùå‚ùå")
            logger.error(f"   Magasin {shop_code}: √âCHEC")
            return False
        
        shop_id = shop_data.get('id')
        if not shop_id:
            logger.error(f"‚ùå‚ùå‚ùå ID DU MAGASIN NON TROUV√â ‚ùå‚ùå‚ùå")
            logger.error(f"   Magasin {shop_code}: √âCHEC")
            return False
        
        # R√©cup√©rer les commandes r√©assort
        logger.info(f"üì• R√©cup√©ration des commandes r√©assort pour le magasin {shop_code}...")
        orders = self.get_orders(base_url, shop_id)
        
        if not orders:
            logger.warning(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è AUCUNE COMMANDE R√âASSORT TROUV√âE ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
            logger.warning(f"   Magasin {shop_code}: Aucune donn√©e")
            return True
        
        logger.info(f"‚úÖ {len(orders)} commandes r√©assort r√©cup√©r√©es au total pour le magasin {shop_code}")
        
        # Exporter vers CSV
        logger.info("=" * 60)
        logger.info(f"üíæ EXPORT CSV - MAGASIN {shop_code}")
        logger.info("=" * 60)
        csv_file = self.export_to_csv(orders, shop_code, shop_name)
        if csv_file:
            logger.info("=" * 60)
            logger.info(f"‚úÖ‚úÖ‚úÖ MAGASIN {shop_code} TRAIT√â AVEC SUCC√àS ‚úÖ‚úÖ‚úÖ")
            logger.info("=" * 60)
            logger.info(f"üìÅ Fichier: {csv_file}")
            logger.info(f"üìä Lignes export√©es: {len(orders):,}")
            logger.info("=" * 60)
            return True
        else:
            logger.error(f"‚ùå‚ùå‚ùå ERREUR LORS DE L'EXPORT ‚ùå‚ùå‚ùå")
            logger.error(f"   Magasin {shop_code}: √âCHEC")
            return False

    def extract_all(self):
        """Extrait les commandes r√©assort pour tous les magasins configur√©s"""
        logger.info("=" * 60)
        logger.info("D√âBUT DE L'EXTRACTION API PROSUMA - COMMANDES R√âASSORT")
        logger.info("=" * 60)
        
        # Cr√©er le dossier local EXPORT
        local_export_dir = os.path.join(self.base_dir, 'EXPORT')
        try:
            os.makedirs(local_export_dir, exist_ok=True)
            logger.info(f"‚úÖ Dossier local EXPORT cr√©√©/v√©rifi√©: {local_export_dir}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier local EXPORT: {e}")
        
        # Cr√©er tous les dossiers r√©seau pour chaque magasin au d√©but
        logger.info("=" * 60)
        logger.info("CR√âATION DES DOSSIERS R√âSEAU")
        logger.info("=" * 60)
        base = self.network_folder_base.replace('/', '\\')
        if base.endswith('\\'):
            base = base[:-1]
        asten_path = f"{base}\\Etats Natacha\\Commande\\PRESENTATION_COMMANDE\\ASTEN"
        
        # Cr√©er le dossier ASTEN s'il n'existe pas
        if create_network_folder(asten_path):
            logger.info(f"‚úÖ Dossier ASTEN cr√©√©/v√©rifi√©: {asten_path}")
        else:
            logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier ASTEN: {asten_path}")
        
        # Cr√©er les dossiers pour chaque magasin
        created_folders = []
        for shop_code in self.shop_codes:
            folder_name = self.get_shop_folder_name(shop_code)
            if folder_name:
                shop_folder_path = os.path.join(asten_path, folder_name)
                if create_network_folder(shop_folder_path):
                    created_folders.append(folder_name)
                    logger.info(f"‚úÖ Dossier cr√©√©/v√©rifi√©: {folder_name}")
        else:
                    logger.warning(f"‚ö†Ô∏è Impossible de cr√©er le dossier: {folder_name}")
        
        logger.info(f"‚úÖ {len(created_folders)} dossiers cr√©√©s/v√©rifi√©s sur {len(self.shop_codes)} magasins")
        logger.info("=" * 60)
        
        successful_shops = 0
        total_shops = len(self.shop_codes)
        failed_shops = []  # Liste des magasins en √©chec avec leur nom
        
        for shop_code in self.shop_codes:
            try:
                logger.info(f"\n{'='*60}")
                logger.info(f"üîÑ TRAITEMENT MAGASIN {shop_code}")
                logger.info(f"{'='*60}")
                
                if self.extract_shop(shop_code):
                    successful_shops += 1
                    logger.info(f"‚úÖ‚úÖ‚úÖ MAGASIN {shop_code} TRAIT√â AVEC SUCC√àS ‚úÖ‚úÖ‚úÖ")
                else:
                    shop_name = self.shop_config.get(shop_code, {}).get('name', 'Nom inconnu')
                    failed_shops.append((shop_code, shop_name))
                    logger.error(f"‚ùå‚ùå‚ùå MAGASIN {shop_code} √âCHEC ‚ùå‚ùå‚ùå")
                    
            except Exception as e:
                shop_name = self.shop_config.get(shop_code, {}).get('name', 'Nom inconnu')
                failed_shops.append((shop_code, shop_name))
                logger.error(f"‚ùå‚ùå‚ùå ERREUR LORS DE L'EXTRACTION DU MAGASIN {shop_code} ‚ùå‚ùå‚ùå")
                logger.error(f"   Erreur: {e}")
        
        # R√©sum√© final
        logger.info(f"\n{'='*60}")
        logger.info("üìäüìäüìä R√âSUM√â FINAL DE L'EXTRACTION üìäüìäüìä")
        logger.info(f"{'='*60}")
        logger.info(f"‚úÖ Magasins trait√©s avec succ√®s: {successful_shops}/{total_shops}")
        logger.info(f"‚ùå Magasins en √©chec: {len(failed_shops)}/{total_shops}")
        
        # Afficher les magasins en erreur s'il y en a
        if failed_shops:
            logger.warning("=" * 60)
            logger.warning("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è EXTRACTION PARTIELLEMENT R√âUSSIE ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
            logger.warning("=" * 60)
            logger.warning("")
            logger.warning("üìãüìãüìã LISTE DES MAGASINS EN √âCHEC üìãüìãüìã")
            logger.warning("=" * 60)
            for shop_code, shop_name in failed_shops:
                logger.warning(f"   ‚ùå Code magasin: {shop_code} - Nom: {shop_name}")
            logger.warning("=" * 60)
            logger.warning("")
        elif successful_shops == total_shops:
            logger.info("=" * 60)
            logger.info("‚úÖ‚úÖ‚úÖ EXTRACTION COMPL√àTEMENT R√âUSSIE ‚úÖ‚úÖ‚úÖ")
            logger.info("=" * 60)
        else:
            logger.error("=" * 60)
            logger.error("‚ùå‚ùå‚ùå AUCUNE EXTRACTION R√âUSSIE ‚ùå‚ùå‚ùå")
            logger.error("=" * 60)

def main():
    """Fonction principale"""
    try:
        extractor = ProsumaAPICommandeReassortExtractor()
        extractor.extract_all()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")

if __name__ == "__main__":
    main()

